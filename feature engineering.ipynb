{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 111), (2324, 111), (9913, 3), (2324, 3))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "DATA_PATH = \"LoLesports_data/\"\n",
    "SEED = 42\n",
    "\n",
    "teams_train = pd.read_csv(f\"{DATA_PATH}teams_train.csv\")\n",
    "teams_test = pd.read_csv(f\"{DATA_PATH}teams_test.csv\")\n",
    "\n",
    "teams_train_target = pd.read_csv(f\"{DATA_PATH}teams_train_target.csv\")\n",
    "teams_test_target = pd.read_csv(f\"{DATA_PATH}teams_test_target.csv\")\n",
    "\n",
    "teams_train.shape, teams_test.shape, teams_train_target.shape, teams_test_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 컬럼 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상대 팀 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_opp_teams = teams_train.groupby(\"gameid\")[\"teamname\"].transform(lambda x: x.iloc[::-1].values).to_frame(\"opp_teamname\")\n",
    "teams_train = pd.concat([teams_train, temp_opp_teams], axis=1)\n",
    "temp_opp_teams = teams_test.groupby(\"gameid\")[\"teamname\"].transform(lambda x: x.iloc[::-1].values).to_frame(\"opp_teamname\")\n",
    "teams_test = pd.concat([teams_test, temp_opp_teams], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 날짜 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_train[\"date\"] = pd.to_datetime(teams_train[\"date\"])\n",
    "teams_test[\"date\"] = pd.to_datetime(teams_test[\"date\"])\n",
    "\n",
    "teams_train[\"year\"] = teams_train[\"date\"].dt.year\n",
    "teams_train[\"month\"] = teams_train[\"date\"].dt.month\n",
    "teams_train[\"day\"] = teams_train[\"date\"].dt.day\n",
    "teams_train[\"hour\"] = teams_train[\"date\"].dt.hour\n",
    "teams_train[\"minute\"] = teams_train[\"date\"].dt.minute\n",
    "\n",
    "teams_test[\"year\"] = teams_test[\"date\"].dt.year\n",
    "teams_test[\"month\"] = teams_test[\"date\"].dt.month\n",
    "teams_test[\"day\"] = teams_test[\"date\"].dt.day\n",
    "teams_test[\"hour\"] = teams_test[\"date\"].dt.hour\n",
    "teams_test[\"minute\"] = teams_test[\"date\"].dt.minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 타입 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"league\", \"split\", \"teamname\", \"opp_teamname\", \"ban1\", \"ban2\", \"ban3\", \"ban4\", \"ban5\", \"pick1\", \"pick2\", \"pick3\", \"pick4\", \"pick5\"]\n",
    "\n",
    "teams_train[cols] = teams_train[cols].astype(\"category\")\n",
    "teams_test[cols] = teams_test[cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 특성 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df에 포함되어 있는 특성을 이용한 토대 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 21), (2324, 21))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_game_features = [\n",
    "    \"gameid\",\n",
    "    \"patch\",\n",
    "    \"side\",\n",
    "    \"league\",\n",
    "    \"teamname\",\n",
    "    \"opp_teamname\",\n",
    "    \"ban1\",\n",
    "    \"ban2\",\n",
    "    \"ban3\",\n",
    "    \"ban4\",\n",
    "    \"ban5\",\n",
    "    \"pick1\",\n",
    "    \"pick2\",\n",
    "    \"pick3\",\n",
    "    \"pick4\",\n",
    "    \"pick5\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"day\",\n",
    "    \"hour\",\n",
    "    \"minute\",\n",
    "]\n",
    "\n",
    "train_ft = teams_train[pre_game_features]\n",
    "test_ft = teams_test[pre_game_features]\n",
    "train_target = teams_train_target[\"result\"]\n",
    "test_target = teams_test_target[\"result\"]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 성능점수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train_ft = train_ft.copy()\n",
    "base_test_ft = test_ft.copy()\n",
    "base_train_target = train_target.copy()\n",
    "base_test_target = test_target.copy()\n",
    "\n",
    "base_pre_game_features = pre_game_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 21), (2324, 21), (9913, 21), (2324, 21))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_train_ft[\"side\"] = base_train_ft[\"side\"].map({\"Blue\": 0, \"Red\": 1}) # 진영 인코딩\n",
    "base_test_ft[\"side\"] = base_test_ft[\"side\"].map({\"Blue\": 0, \"Red\": 1})\n",
    "\n",
    "cat_base_train_ft = base_train_ft.copy()\n",
    "cat_base_test_ft = base_test_ft.copy()\n",
    "cat_features = cat_base_train_ft.select_dtypes(\"category\").columns\n",
    "\n",
    "base_train_ft.shape, base_test_ft.shape, cat_base_train_ft.shape, cat_base_test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 28), (2324, 28))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def preprocess(train_ft, test_ft, pre_game_features):\n",
    "    champion_columns_teams = ['ban1', 'ban2', 'ban3', 'ban4', 'ban5', 'pick1', 'pick2', 'pick3', 'pick4', 'pick5'] # 챔피언 레이블인코딩\n",
    "\n",
    "    champions = pd.concat([\n",
    "        train_ft[champion_columns_teams],\n",
    "        test_ft[champion_columns_teams],\n",
    "    ]).stack().unique()\n",
    "\n",
    "    champions_df = pd.DataFrame({'champion': champions})\n",
    "    champions_df = champions_df.dropna().reset_index(drop=True)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    champions_df['champion_encoded'] = le.fit_transform(champions_df['champion'])\n",
    "\n",
    "    for col in champion_columns_teams:\n",
    "        train_ft[col] = le.transform(train_ft[col])\n",
    "        test_ft[col] = le.transform(test_ft[col])\n",
    "        \n",
    "    encoder = OneHotEncoder() # 리그 원핫인코딩\n",
    "    league_encoded = encoder.fit_transform(train_ft[[\"league\"]]).toarray()\n",
    "    pre_game_features.extend(encoder.get_feature_names_out())\n",
    "    league_cols = [f\"league_{col}\" for col in encoder.categories_[0]]\n",
    "    train_ft = pd.concat(\n",
    "        [train_ft, pd.DataFrame(league_encoded, columns=league_cols)], axis=1\n",
    "    )\n",
    "    train_ft.drop(\"league\", axis=1, inplace=True)\n",
    "\n",
    "    league_encoded = encoder.transform(test_ft[[\"league\"]]).toarray()\n",
    "    test_ft = pd.concat(\n",
    "        [test_ft, pd.DataFrame(league_encoded, columns=league_cols)], axis=1\n",
    "    )\n",
    "    test_ft.drop(\"league\", axis=1, inplace=True)\n",
    "\n",
    "    le_team = LabelEncoder()\n",
    "    all_team_names = pd.concat(\n",
    "        [\n",
    "            train_ft[\"teamname\"],\n",
    "            test_ft[\"teamname\"],\n",
    "            train_ft[\"opp_teamname\"],\n",
    "            test_ft[\"opp_teamname\"],\n",
    "        ]\n",
    "    )\n",
    "    le_team.fit(all_team_names)\n",
    "\n",
    "    train_ft[\"teamname\"] = le_team.transform(train_ft[\"teamname\"])\n",
    "    train_ft[\"opp_teamname\"] = le_team.transform(train_ft[\"opp_teamname\"])\n",
    "\n",
    "    test_ft[\"teamname\"] = le_team.transform(test_ft[\"teamname\"])\n",
    "    test_ft[\"opp_teamname\"] = le_team.transform(test_ft[\"opp_teamname\"])\n",
    "    \n",
    "    return train_ft, test_ft, pre_game_features\n",
    "\n",
    "base_train_ft, base_test_ft, base_pre_game_features = preprocess(base_train_ft, base_test_ft, base_pre_game_features)\n",
    "\n",
    "base_train_ft.shape, base_test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 28), (2324, 28), (9913, 21), (2324, 21))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "def scale(train_ft, test_ft):\n",
    "    train_ft[train_ft.select_dtypes(\"number\").columns] = scaler.fit_transform(\n",
    "        train_ft[train_ft.select_dtypes(\"number\").columns]\n",
    "    )\n",
    "    test_ft[test_ft.select_dtypes(\"number\").columns] = scaler.transform(\n",
    "        test_ft[test_ft.select_dtypes(\"number\").columns]\n",
    "    )\n",
    "    return train_ft, test_ft\n",
    "\n",
    "\n",
    "base_train_ft, base_test_ft = scale(base_train_ft, base_test_ft)\n",
    "cat_base_train_ft, cat_base_test_ft = scale(cat_base_train_ft, cat_base_test_ft)\n",
    "\n",
    "base_train_ft.shape, base_test_ft.shape, cat_base_train_ft.shape, cat_base_test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7799, 27), (2114, 27))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_patch = base_train_ft[\"patch\"].quantile(0.8)\n",
    "train_games = base_train_ft[base_train_ft[\"patch\"] < cutoff_patch][\"gameid\"].unique()\n",
    "valid_games = base_train_ft[base_train_ft[\"patch\"] >= cutoff_patch][\"gameid\"].unique()\n",
    "\n",
    "base_train_x = base_train_ft[base_train_ft[\"gameid\"].isin(train_games)]\n",
    "base_valid_x = base_train_ft[base_train_ft[\"gameid\"].isin(valid_games)]\n",
    "\n",
    "base_train_y = teams_train_target[teams_train_target[\"gameid\"].isin(train_games)][\"result\"]\n",
    "base_valid_y = teams_train_target[teams_train_target[\"gameid\"].isin(valid_games)][\"result\"]\n",
    "\n",
    "base_train_x = base_train_x.drop(columns=[\"gameid\"])\n",
    "base_valid_x = base_valid_x.drop(columns=[\"gameid\"])\n",
    "\n",
    "base_train_x.shape, base_valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7799, 20), (2114, 20))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_base_train_games = cat_base_train_ft[cat_base_train_ft[\"patch\"] < cutoff_patch][\"gameid\"].unique()\n",
    "cat_base_valid_games = cat_base_train_ft[cat_base_train_ft[\"patch\"] >= cutoff_patch][\"gameid\"].unique()\n",
    "\n",
    "cat_base_train_x = cat_base_train_ft[cat_base_train_ft[\"gameid\"].isin(cat_base_train_games)]\n",
    "cat_base_valid_x = cat_base_train_ft[cat_base_train_ft[\"gameid\"].isin(cat_base_valid_games)]\n",
    "\n",
    "cat_base_train_y = teams_train_target[teams_train_target[\"gameid\"].isin(cat_base_train_games)][\"result\"]\n",
    "cat_base_valid_y = teams_train_target[teams_train_target[\"gameid\"].isin(cat_base_valid_games)][\"result\"]\n",
    "\n",
    "cat_base_train_x = cat_base_train_x.drop(columns=[\"gameid\"])\n",
    "cat_base_valid_x = cat_base_valid_x.drop(columns=[\"gameid\"])\n",
    "\n",
    "cat_base_train_x.shape, cat_base_valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_test_ft = base_test_ft.drop(columns=[\"gameid\"])\n",
    "cat_base_test_ft = cat_base_test_ft.drop(columns=[\"gameid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_train_x.to_csv(\"vis/data/base_train_x.csv\", index=False)\n",
    "# base_valid_x.to_csv(\"vis/data/base_valid_x.csv\", index=False)\n",
    "# base_test_ft.to_csv(\"vis/data/base_test_ft.csv\", index=False)\n",
    "# cat_base_train_x.to_csv(\"vis/data/cat_base_train_x.csv\", index=False)\n",
    "# cat_base_valid_x.to_csv(\"vis/data/cat_base_valid_x.csv\", index=False)\n",
    "# cat_base_test_ft.to_csv(\"vis/data/cat_base_test_ft.csv\", index=False)\n",
    "# base_train_y.to_csv(\"vis/data/base_train_y.csv\", index=False)\n",
    "# base_valid_y.to_csv(\"vis/data/base_valid_y.csv\", index=False)\n",
    "# base_test_target.to_csv(\"vis/data/base_test_target.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 검증 데이터 성능점수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression - Accuracy: 0.5058, ROC AUC: 0.5200\n",
      "LGBMClassifier - Accuracy: 0.5841, ROC AUC: 0.6167\n",
      "RandomForestClassifier - Accuracy: 0.5509, ROC AUC: 0.5664\n",
      "HistGradientBoostingClassifier - Accuracy: 0.5832, ROC AUC: 0.6133\n",
      "AdaBoostClassifier - Accuracy: 0.5567, ROC AUC: 0.5816\n",
      "SVC - Accuracy: 0.5093, ROC AUC: 0.5185\n",
      "XGBClassifier - Accuracy: 0.5723, ROC AUC: 0.6008\n",
      "CatBoostClassifier - Accuracy: 0.6097, ROC AUC: 0.6567\n"
     ]
    }
   ],
   "source": [
    "cat_features = cat_base_train_x.select_dtypes(\"category\").columns.tolist()\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(random_state=SEED),\n",
    "    LGBMClassifier(random_state=SEED, n_jobs=-1, verbose=-1),\n",
    "    RandomForestClassifier(random_state=SEED, n_jobs=-1),\n",
    "    HistGradientBoostingClassifier(random_state=SEED),\n",
    "    AdaBoostClassifier(random_state=SEED, algorithm=\"SAMME\"),\n",
    "    SVC(random_state=SEED, probability=True),\n",
    "    XGBClassifier(random_state=SEED, n_jobs=-1),\n",
    "    CatBoostClassifier(random_state=SEED, verbose=0, cat_features=cat_features),\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    if model.__class__.__name__ == \"CatBoostClassifier\":\n",
    "        valid_acc = cross_val_score(model, cat_base_train_x, cat_base_train_y, cv=TimeSeriesSplit(5), scoring=\"accuracy\", n_jobs=-1)\n",
    "        valid_roc_auc = cross_val_score(model, cat_base_train_x, cat_base_train_y, cv=TimeSeriesSplit(5), scoring=\"roc_auc\", n_jobs=-1)\n",
    "        print(f\"{model.__class__.__name__} - Accuracy: {np.mean(valid_acc):.4f}, ROC AUC: {np.mean(valid_roc_auc):.4f}\")\n",
    "    else:\n",
    "        valid_acc = cross_val_score(model, base_train_x, base_train_y, cv=TimeSeriesSplit(5), scoring=\"accuracy\", n_jobs=-1)\n",
    "        valid_roc_auc = cross_val_score(model, base_train_x, base_train_y, cv=TimeSeriesSplit(5), scoring=\"roc_auc\", n_jobs=-1)\n",
    "        print(f\"{model.__class__.__name__} - Accuracy: {np.mean(valid_acc):.4f}, ROC AUC: {np.mean(valid_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테스트 데이터 성능점수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression - Accuracy: 0.5297, ROC AUC: 0.5339\n",
      "LGBMClassifier - Accuracy: 0.6196, ROC AUC: 0.6657\n",
      "RandomForestClassifier - Accuracy: 0.5757, ROC AUC: 0.6124\n",
      "HistGradientBoostingClassifier - Accuracy: 0.6256, ROC AUC: 0.6740\n",
      "AdaBoostClassifier - Accuracy: 0.5830, ROC AUC: 0.6269\n",
      "SVC - Accuracy: 0.5284, ROC AUC: 0.5328\n",
      "XGBClassifier - Accuracy: 0.5968, ROC AUC: 0.6365\n",
      "CatBoostClassifier - Accuracy: 0.6183, ROC AUC: 0.6769\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    if model.__class__.__name__ == \"CatBoostClassifier\":\n",
    "        model.fit(pd.concat([cat_base_train_x, cat_base_valid_x]), pd.concat([cat_base_train_y, cat_base_valid_y]))\n",
    "        test_pred = model.predict(cat_base_test_ft)\n",
    "        test_pred_proba = model.predict_proba(cat_base_test_ft)[:, 1]\n",
    "        print(f\"{model.__class__.__name__} - Accuracy: {accuracy_score(teams_test_target['result'], test_pred):.4f}, ROC AUC: {roc_auc_score(teams_test_target['result'], test_pred_proba):.4f}\")\n",
    "    else:\n",
    "        model.fit(pd.concat([base_train_x, base_valid_x]), pd.concat([base_train_y, base_valid_y]))\n",
    "        test_pred = model.predict(base_test_ft)\n",
    "        test_pred_proba = model.predict_proba(base_test_ft)[:, 1]\n",
    "        print(f\"{model.__class__.__name__} - Accuracy: {accuracy_score(teams_test_target['result'], test_pred):.4f}, ROC AUC: {roc_auc_score(teams_test_target['result'], test_pred_proba):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "\n",
    "# cat_features = cat_base_train_x.select_dtypes(\"category\").columns.tolist()\n",
    "\n",
    "\n",
    "# def train_and_evaluate(\n",
    "#     train_x,\n",
    "#     valid_x,\n",
    "#     test_x,\n",
    "#     cat_train_x,\n",
    "#     cat_valid_x,\n",
    "#     cat_test_x,\n",
    "#     train_y,\n",
    "#     valid_y,\n",
    "#     test_y,\n",
    "#     cat_features,\n",
    "#     use_additional_data=False,\n",
    "# ):\n",
    "#     models = {\n",
    "#         \"lr\": LogisticRegression(random_state=SEED),\n",
    "#         \"lgbm\": LGBMClassifier(random_state=SEED, n_jobs=-1),\n",
    "#         \"rf\": RandomForestClassifier(random_state=SEED, n_jobs=-1),\n",
    "#         \"hgbc\": HistGradientBoostingClassifier(random_state=SEED),\n",
    "#         \"ada\": AdaBoostClassifier(random_state=SEED),\n",
    "#         \"svc\": SVC(random_state=SEED, probability=True),\n",
    "#         \"xgb\": XGBClassifier(random_state=SEED, n_jobs=-1),\n",
    "#         \"cat\": CatBoostClassifier(\n",
    "#             random_state=SEED, verbose=0, cat_features=cat_features\n",
    "#         ),\n",
    "#     }\n",
    "\n",
    "#     for name, model in models.items():\n",
    "#         run_name_suffix = \"additional\" if use_additional_data else \"base\"\n",
    "        \n",
    "#         if wandb.run is not None:\n",
    "#             wandb.finish()\n",
    "            \n",
    "#         wandb.init(\n",
    "#             project=\"temp-lol-match-prediction2\",\n",
    "#             name=f\"{name}_{run_name_suffix}\",\n",
    "#             config={\"seed\": SEED},\n",
    "#         )\n",
    "\n",
    "#         if name == \"cat\":\n",
    "#             model.fit(cat_train_x, train_y)\n",
    "#             valid_accuracy = accuracy_score(valid_y, model.predict(cat_valid_x))\n",
    "#             valid_roc_auc = roc_auc_score(\n",
    "#                 valid_y, model.predict_proba(cat_valid_x)[:, 1]\n",
    "#             )\n",
    "#             test_accuracy = accuracy_score(test_y, model.predict(cat_test_x))\n",
    "#             test_roc_auc = roc_auc_score(test_y, model.predict_proba(cat_test_x)[:, 1])\n",
    "#         else:\n",
    "#             model.fit(train_x, train_y)\n",
    "#             valid_accuracy = accuracy_score(valid_y, model.predict(valid_x))\n",
    "#             valid_roc_auc = roc_auc_score(valid_y, model.predict_proba(valid_x)[:, 1])\n",
    "#             test_accuracy = accuracy_score(test_y, model.predict(test_x))\n",
    "#             test_roc_auc = roc_auc_score(test_y, model.predict_proba(test_x)[:, 1])\n",
    "\n",
    "#         wandb.log(\n",
    "#             {\n",
    "#                 \"valid_accuracy\": valid_accuracy,\n",
    "#                 \"valid_roc_auc\": valid_roc_auc,\n",
    "#                 \"test_accuracy\": test_accuracy,\n",
    "#                 \"test_roc_auc\": test_roc_auc,\n",
    "#                 \"model\": name,\n",
    "#                 \"feature_type\": \"base\" if not use_additional_data else \"additional\",\n",
    "#             }\n",
    "#         )\n",
    "#         wandb.finish()\n",
    "\n",
    "\n",
    "# train_and_evaluate(\n",
    "#     base_train_x,\n",
    "#     base_valid_x,\n",
    "#     base_test_ft,\n",
    "#     cat_base_train_x,\n",
    "#     cat_base_valid_x,\n",
    "#     cat_base_test_ft,\n",
    "#     base_train_y,\n",
    "#     base_valid_y,\n",
    "#     base_test_target,\n",
    "#     cat_features,\n",
    "#     use_additional_data=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 팀별 최근 10경기 지표 계산, 상대팀 최근 10경기 지표 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_columns = [\n",
    "    \"result\",\n",
    "    \"gamelength\",\n",
    "    \"kills\",\n",
    "    \"deaths\",\n",
    "    \"assists\",\n",
    "    \"firstblood\",\n",
    "    \"team kpm\",\n",
    "    \"ckpm\",\n",
    "    \"firstdragon\",\n",
    "    \"firstherald\",\n",
    "    \"void_grubs\",\n",
    "    \"firstbaron\",\n",
    "    \"firsttower\",\n",
    "    \"towers\",\n",
    "    \"firstmidtower\",\n",
    "    \"firsttothreetowers\",\n",
    "    \"turretplates\",\n",
    "    \"inhibitors\",\n",
    "    \"damagetochampions\",\n",
    "    \"dpm\",\n",
    "    \"damagetakenperminute\",\n",
    "    \"damagemitigatedperminute\",\n",
    "    \"wardsplaced\",\n",
    "    \"wpm\",\n",
    "    \"wardskilled\",\n",
    "    \"wcpm\",\n",
    "    \"controlwardsbought\",\n",
    "    \"visionscore\",\n",
    "    \"vspm\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 79), (2324, 79))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 팀별 최근 승률 계산을 위한 데이터 정렬\n",
    "temp_train = teams_train.sort_values([\"teamname\", \"year\", \"month\", \"day\", \"hour\", \"minute\"]).reset_index(drop=True)\n",
    "temp_test = teams_test.sort_values([\"teamname\", \"year\", \"month\", \"day\", \"hour\", \"minute\"]).reset_index(drop=True)\n",
    "\n",
    "# 팀별 최근 10경기 평균 계산\n",
    "for col in stats_columns:\n",
    "    # 승률 계산\n",
    "    recent10_train = temp_train.groupby(\"teamname\", observed=True)[col].transform(\n",
    "        lambda x: x.rolling(window=10, min_periods=1).mean().shift(1)\n",
    "    )\n",
    "    train_ft = train_ft.assign(**{f\"recent10_{col}\": recent10_train})\n",
    "\n",
    "    # 테스트 데이터의 지표 계산을 위해 훈련 데이터와 테스트 데이터 결합\n",
    "    combined_data = pd.concat([temp_train, temp_test], ignore_index=True).sort_values(\n",
    "        [\"teamname\", \"year\", \"month\", \"day\", \"hour\", \"minute\"]\n",
    "    )\n",
    "    recent10_combined = combined_data.groupby(\"teamname\", observed=True)[col].transform(\n",
    "        lambda x: x.rolling(window=10, min_periods=1).mean().shift(1)\n",
    "    )\n",
    "    combined_data = combined_data.assign(**{f\"recent10_{col}\": recent10_combined})\n",
    "\n",
    "    # 테스트 데이터의 지표 업데이트\n",
    "    recent10_test = combined_data.tail(len(temp_test))[f\"recent10_{col}\"].values\n",
    "    test_ft = test_ft.assign(**{f\"recent10_{col}\": recent10_test})\n",
    "\n",
    "    # 상대팀 최근 지표 계산\n",
    "    merged_train = train_ft.merge(\n",
    "        train_ft[[\"teamname\", \"year\", \"month\", \"day\", \"hour\", \"minute\", f\"recent10_{col}\"]],\n",
    "        left_on=[\"opp_teamname\", \"year\", \"month\", \"day\", \"hour\", \"minute\"],\n",
    "        right_on=[\"teamname\", \"year\", \"month\", \"day\", \"hour\", \"minute\"],\n",
    "        suffixes=(\"\", \"_opp\"),\n",
    "    )\n",
    "    train_ft = train_ft.assign(\n",
    "        **{f\"opp_recent10_{col}\": merged_train[f\"recent10_{col}_opp\"]}\n",
    "    )\n",
    "\n",
    "    merged_test = test_ft.merge(\n",
    "        combined_data[[\"teamname\", \"year\", \"month\", \"day\", \"hour\", \"minute\", f\"recent10_{col}\"]],\n",
    "        left_on=[\"opp_teamname\", \"year\", \"month\", \"day\", \"hour\", \"minute\"],\n",
    "        right_on=[\"teamname\", \"year\", \"month\", \"day\", \"hour\", \"minute\"],\n",
    "        suffixes=(\"\", \"_opp\"),\n",
    "    )\n",
    "    test_ft = test_ft.assign(\n",
    "        **{f\"opp_recent10_{col}\": merged_test[f\"recent10_{col}_opp\"]}\n",
    "    )\n",
    "\n",
    "    # NaN값 처리 (첫 경기인 경우)\n",
    "    default_value = 0.5 if col == \"result\" else 0\n",
    "    train_ft = train_ft.assign(\n",
    "        **{\n",
    "            f\"recent10_{col}\": train_ft[f\"recent10_{col}\"].fillna(default_value),\n",
    "            f\"opp_recent10_{col}\": train_ft[f\"opp_recent10_{col}\"].fillna(\n",
    "                default_value\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "    test_ft = test_ft.assign(\n",
    "        **{\n",
    "            f\"recent10_{col}\": test_ft[f\"recent10_{col}\"].fillna(default_value),\n",
    "            f\"opp_recent10_{col}\": test_ft[f\"opp_recent10_{col}\"].fillna(default_value),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 특성 리스트에 새로운 지표 추가\n",
    "    pre_game_features.extend([f\"recent10_{col}\", f\"opp_recent10_{col}\"])\n",
    "\n",
    "# 입력 데이터 업데이트\n",
    "train_ft = train_ft[pre_game_features]\n",
    "test_ft = test_ft[pre_game_features]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상대 전적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 80), (2324, 80))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 팀별 맞대결 기록을 시간순으로 계산\n",
    "h2h_records = {}\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 결합 후 시간순 정렬\n",
    "combined_data = pd.concat([teams_train, teams_test], ignore_index=True)\n",
    "combined_data = combined_data.sort_values(['year', 'month', 'day', 'hour', 'minute'])\n",
    "\n",
    "# 각 경기마다 이전 맞대결 기록 계산\n",
    "h2h_winrates = []\n",
    "\n",
    "for idx, match in combined_data.iterrows():\n",
    "    team1, team2 = match['teamname'], match['opp_teamname']\n",
    "    year = match['year']\n",
    "    key = (team1, team2, year)\n",
    "    \n",
    "    # 현재 시점까지의 맞대결 기록 저장\n",
    "    if key not in h2h_records:\n",
    "        h2h_records[key] = {'wins': 0, 'total': 0}\n",
    "        h2h_winrates.append(0.5)  # 첫 맞대결인 경우 0.5 반환\n",
    "    else:\n",
    "        record = h2h_records[key]\n",
    "        h2h_winrates.append(record['wins'] / record['total'] if record['total'] > 0 else 0.5)\n",
    "    \n",
    "    # 현재 경기 결과 반영\n",
    "    result = match['result']\n",
    "    h2h_records[key]['total'] += 1\n",
    "    if result == 1:\n",
    "        h2h_records[key]['wins'] += 1\n",
    "        \n",
    "    # 상대팀 관점의 기록도 업데이트\n",
    "    key_reverse = (team2, team1, year)\n",
    "    if key_reverse not in h2h_records:\n",
    "        h2h_records[key_reverse] = {'wins': 0, 'total': 0}\n",
    "    h2h_records[key_reverse]['total'] += 1\n",
    "    if result == 0:\n",
    "        h2h_records[key_reverse]['wins'] += 1\n",
    "\n",
    "# 계산된 승률을 훈련/테스트 데이터에 할당\n",
    "train_ft['h2h_winrate'] = h2h_winrates[:len(teams_train)]\n",
    "test_ft['h2h_winrate'] = h2h_winrates[len(teams_train):]\n",
    "\n",
    "# 특성 리스트에 h2h_winrate 추가\n",
    "pre_game_features.append('h2h_winrate')\n",
    "\n",
    "# 입력 데이터 업데이트\n",
    "train_ft = train_ft[pre_game_features]\n",
    "test_ft = test_ft[pre_game_features]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 팀의 리그별 승률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 81), (2324, 81))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 팀별 리그 승률 기록을 저장할 딕셔너리\n",
    "league_records = {}\n",
    "league_winrates = []\n",
    "\n",
    "# 날짜순으로 정렬\n",
    "combined_data = pd.concat([teams_train, teams_test], ignore_index=True)\n",
    "combined_data = combined_data.sort_values(['year', 'month', 'day', 'hour', 'minute'])\n",
    "\n",
    "# 훈련 데이터에서 팀별 리그 승률 계산\n",
    "for idx, match in combined_data.iterrows():\n",
    "    team = match['teamname']\n",
    "    league = match['league']\n",
    "    year = match['year']\n",
    "    key = (team, league, year)\n",
    "    \n",
    "    # 현재 시점까지의 리그 승률 계산\n",
    "    if key not in league_records:\n",
    "        league_records[key] = {'wins': 0, 'total': 0}\n",
    "        league_winrates.append(0.5)  # 첫 경기인 경우 0.5 반환\n",
    "    else:\n",
    "        record = league_records[key]\n",
    "        league_winrates.append(record['wins'] / record['total'] if record['total'] > 0 else 0.5)\n",
    "    \n",
    "    # 현재 경기 결과 반영\n",
    "    result = match['result']\n",
    "    league_records[key]['total'] += 1\n",
    "    if result == 1:\n",
    "        league_records[key]['wins'] += 1\n",
    "\n",
    "# 계산된 승률을 훈련/테스트 데이터에 할당\n",
    "train_ft['league_winrate'] = league_winrates[:len(teams_train)]\n",
    "test_ft['league_winrate'] = league_winrates[len(teams_train):]\n",
    "\n",
    "# 특성 리스트에 league_winrate 추가\n",
    "pre_game_features.append('league_winrate')\n",
    "\n",
    "# 입력 데이터 업데이트\n",
    "train_ft = train_ft[pre_game_features]\n",
    "test_ft = test_ft[pre_game_features]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft[\"side\"] = train_ft[\"side\"].map({\"Blue\": 0, \"Red\": 1}) # 진영 인코딩\n",
    "test_ft[\"side\"] = test_ft[\"side\"].map({\"Blue\": 0, \"Red\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_data = pd.concat([train_ft, test_ft], ignore_index=True)\n",
    "featured_data.to_csv(\"LoLesports_data/featured_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train_ft = train_ft.copy()\n",
    "cat_test_ft = test_ft.copy()\n",
    "cat_pre_game_features = pre_game_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft, test_ft, pre_game_features = preprocess(train_ft, test_ft, pre_game_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['gameid'], dtype='object'), Index(['gameid'], dtype='object'))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.select_dtypes(\"object\").columns, test_ft.select_dtypes(\"object\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 88), (2324, 88), (9913, 81), (2324, 81))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft, test_ft = scale(train_ft, test_ft)\n",
    "cat_train_ft, cat_test_ft = scale(cat_train_ft, cat_test_ft)\n",
    "\n",
    "train_ft.shape, test_ft.shape, cat_train_ft.shape, cat_test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7799, 87), (2114, 87))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_patch = train_ft[\"patch\"].quantile(0.8)\n",
    "train_games = train_ft[train_ft[\"patch\"] < cutoff_patch][\"gameid\"].unique()\n",
    "valid_games = train_ft[train_ft[\"patch\"] >= cutoff_patch][\"gameid\"].unique()\n",
    "\n",
    "train_x = train_ft[train_ft[\"gameid\"].isin(train_games)]\n",
    "valid_x = train_ft[train_ft[\"gameid\"].isin(valid_games)]\n",
    "\n",
    "train_y = teams_train_target[teams_train_target[\"gameid\"].isin(train_games)][\"result\"]\n",
    "valid_y = teams_train_target[teams_train_target[\"gameid\"].isin(valid_games)][\"result\"]\n",
    "\n",
    "train_x = train_x.drop(columns=[\"gameid\"])\n",
    "valid_x = valid_x.drop(columns=[\"gameid\"])\n",
    "\n",
    "train_x.shape, valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = teams_train_target[teams_train_target[\"gameid\"].isin(valid_games)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7799, 80), (2114, 80))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_train_games = cat_train_ft[cat_train_ft[\"patch\"] < cutoff_patch][\"gameid\"].unique()\n",
    "cat_valid_games = cat_train_ft[cat_train_ft[\"patch\"] >= cutoff_patch][\"gameid\"].unique()\n",
    "\n",
    "cat_train_x = cat_train_ft[cat_train_ft[\"gameid\"].isin(cat_train_games)]\n",
    "cat_valid_x = cat_train_ft[cat_train_ft[\"gameid\"].isin(cat_valid_games)]\n",
    "\n",
    "cat_train_y = teams_train_target[teams_train_target[\"gameid\"].isin(cat_train_games)][\"result\"]\n",
    "cat_valid_y = teams_train_target[teams_train_target[\"gameid\"].isin(cat_valid_games)][\"result\"]\n",
    "\n",
    "cat_train_x = cat_train_x.drop(columns=[\"gameid\"])\n",
    "cat_valid_x = cat_valid_x.drop(columns=[\"gameid\"])\n",
    "\n",
    "cat_train_x.shape, cat_valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ft = test_ft.drop(columns=[\"gameid\"])\n",
    "cat_test_ft = cat_test_ft.drop(columns=[\"gameid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression - Valid Accuracy: 0.6667, Valid ROC AUC: 0.7349\n",
      "LGBMClassifier - Valid Accuracy: 0.7238, Valid ROC AUC: 0.8074\n",
      "RandomForestClassifier - Valid Accuracy: 0.6593, Valid ROC AUC: 0.7304\n",
      "HistGradientBoostingClassifier - Valid Accuracy: 0.7132, Valid ROC AUC: 0.8014\n",
      "AdaBoostClassifier - Valid Accuracy: 0.6654, Valid ROC AUC: 0.7353\n",
      "SVC - Valid Accuracy: 0.6650, Valid ROC AUC: 0.7356\n",
      "XGBClassifier - Valid Accuracy: 0.7149, Valid ROC AUC: 0.8019\n",
      "CatBoostClassifier - Valid Accuracy: 0.7159, Valid ROC AUC: 0.8206\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    if model.__class__.__name__ == \"CatBoostClassifier\":\n",
    "        valid_acc = cross_val_score(model, cat_valid_x, cat_valid_y, cv=TimeSeriesSplit(5), scoring=\"accuracy\", n_jobs=-1)\n",
    "        valid_roc_auc = cross_val_score(model, cat_valid_x, cat_valid_y, cv=TimeSeriesSplit(5), scoring=\"roc_auc\", n_jobs=-1)\n",
    "        print(f\"{model.__class__.__name__} - Valid Accuracy: {np.mean(valid_acc):.4f}, Valid ROC AUC: {np.mean(valid_roc_auc):.4f}\")\n",
    "    else:\n",
    "        valid_acc = cross_val_score(model, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"accuracy\", n_jobs=-1)\n",
    "        valid_roc_auc = cross_val_score(model, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"roc_auc\", n_jobs=-1)\n",
    "        print(f\"{model.__class__.__name__} - Valid Accuracy: {np.mean(valid_acc):.4f}, Valid ROC AUC: {np.mean(valid_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression - Accuracy: 0.6609, ROC AUC: 0.7195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kwon3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier - Accuracy: 0.7560, ROC AUC: 0.8391\n",
      "RandomForestClassifier - Accuracy: 0.6515, ROC AUC: 0.7053\n",
      "HistGradientBoostingClassifier - Accuracy: 0.7496, ROC AUC: 0.8394\n",
      "AdaBoostClassifier - Accuracy: 0.6743, ROC AUC: 0.7397\n",
      "SVC - Accuracy: 0.6566, ROC AUC: 0.7221\n",
      "XGBClassifier - Accuracy: 0.7173, ROC AUC: 0.7958\n",
      "CatBoostClassifier - Accuracy: 0.7207, ROC AUC: 0.8052\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    if model.__class__.__name__ == \"CatBoostClassifier\":\n",
    "        model.fit(pd.concat([cat_train_x, cat_valid_x]), pd.concat([cat_train_y, cat_valid_y]))\n",
    "        test_pred = model.predict(cat_test_ft)\n",
    "        test_pred_proba = model.predict_proba(cat_test_ft)[:, 1]\n",
    "        print(f\"{model.__class__.__name__} - Accuracy: {accuracy_score(teams_test_target['result'], test_pred):.4f}, ROC AUC: {roc_auc_score(teams_test_target['result'], test_pred_proba):.4f}\")\n",
    "    else:\n",
    "        model.fit(pd.concat([train_x, valid_x]), pd.concat([train_y, valid_y]))\n",
    "        test_pred = model.predict(test_ft)\n",
    "        test_pred_proba = model.predict_proba(test_ft)[:, 1]\n",
    "        print(f\"{model.__class__.__name__} - Accuracy: {accuracy_score(teams_test_target['result'], test_pred):.4f}, ROC AUC: {roc_auc_score(teams_test_target['result'], test_pred_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x.to_csv(\"vis/data/train_x.csv\", index=False)\n",
    "# valid_x.to_csv(\"vis/data/valid_x.csv\", index=False)\n",
    "# test_ft.to_csv(\"vis/data/test_ft.csv\", index=False)\n",
    "# cat_train_x.to_csv(\"vis/data/cat_train_x.csv\", index=False)\n",
    "# cat_valid_x.to_csv(\"vis/data/cat_valid_x.csv\", index=False)\n",
    "# cat_test_ft.to_csv(\"vis/data/cat_test_ft.csv\", index=False)\n",
    "# train_y.to_csv(\"vis/data/train_y.csv\", index=False)\n",
    "# valid_y.to_csv(\"vis/data/valid_y.csv\", index=False)\n",
    "# test_target.to_csv(\"vis/data/test_target.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_evaluate(\n",
    "#     train_x,\n",
    "#     valid_x,\n",
    "#     test_ft,\n",
    "#     cat_train_x,\n",
    "#     cat_valid_x,\n",
    "#     cat_test_ft,\n",
    "#     train_y,\n",
    "#     valid_y,\n",
    "#     test_target,\n",
    "#     cat_features,\n",
    "#     use_additional_data=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습 및 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하이퍼파라미터 튜닝 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "\n",
    "class HyperparameterTuner:\n",
    "    def __init__(self, model, params, train, target, cat_features=None):\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "        self.train = train\n",
    "        self.target = target\n",
    "        self.cat_features = cat_features\n",
    "        self.cv = TimeSeriesSplit(n_splits=5)\n",
    "        self.study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "    def objective(self, trial):\n",
    "        params = {}\n",
    "        \n",
    "        for param_name, param_range in self.params.items():\n",
    "            if param_range[\"type\"] == \"int\":\n",
    "                params[param_name] = trial.suggest_int(\n",
    "                    param_name, param_range[\"min\"], param_range[\"max\"]\n",
    "                )\n",
    "            elif param_range[\"type\"] == \"float\":\n",
    "                params[param_name] = trial.suggest_float(\n",
    "                    param_name, param_range[\"min\"], param_range[\"max\"]\n",
    "                )\n",
    "            elif param_range[\"type\"] == \"categorical\":\n",
    "                params[param_name] = trial.suggest_categorical(\n",
    "                    param_name, param_range[\"values\"]\n",
    "                )\n",
    "        if self.model == CatBoostClassifier:\n",
    "            model = self.model(**params, cat_features=self.cat_features)\n",
    "        else:\n",
    "            model = self.model(**params)\n",
    "\n",
    "        model.fit(self.train, self.target)\n",
    "            \n",
    "        scores = cross_val_score(\n",
    "            model, self.train, self.target, cv=self.cv, scoring=\"accuracy\", n_jobs=-1\n",
    "        ).mean()\n",
    "        return scores\n",
    "\n",
    "    def optimize(self, n_trials):\n",
    "        self.study.optimize(self.objective, n_trials=n_trials)\n",
    "\n",
    "    def best_params(self):\n",
    "        return self.study.best_params\n",
    "\n",
    "    def best_score(self):\n",
    "        return self.study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모든 컬럼 형식이 number인 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"C\": {\"type\": \"float\", \"min\": 0.01, \"max\": 10},\n",
    "#     \"penalty\": {\"type\": \"categorical\", \"values\": [\"l1\", \"l2\"]},\n",
    "#     \"solver\": {\"type\": \"categorical\", \"values\": [\"liblinear\", \"saga\"]},\n",
    "#     \"max_iter\": {\"type\": \"int\", \"min\": 100, \"max\": 2000},\n",
    "# }\n",
    "\n",
    "# lr_vt_tuner = HyperparameterTuner(LogisticRegression, params, train_x, train_y)\n",
    "# lr_vt_tuner.optimize(100)\n",
    "# lr_vt_tuner.best_params(), lr_vt_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68      1060\n",
      "           1       0.67      0.73      0.70      1054\n",
      "\n",
      "    accuracy                           0.69      2114\n",
      "   macro avg       0.69      0.69      0.69      2114\n",
      "weighted avg       0.69      0.69      0.69      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"C\": 0.38414964961856957,\n",
    "    \"penalty\": \"l1\",\n",
    "    \"solver\": \"liblinear\",\n",
    "    \"max_iter\": 1903\n",
    "}\n",
    "\n",
    "lr_tuned = LogisticRegression(**params)\n",
    "lr_tuned.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, lr_tuned.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6717, ROC AUC: 0.7385\n"
     ]
    }
   ],
   "source": [
    "valid_acc = cross_val_score(lr_tuned, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"accuracy\", n_jobs=-1)\n",
    "valid_roc_auc = cross_val_score(lr_tuned, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"roc_auc\", n_jobs=-1)\n",
    "print(f\"Accuracy: {np.mean(valid_acc):.4f}, ROC AUC: {np.mean(valid_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6756, ROC AUC: 0.7258\n"
     ]
    }
   ],
   "source": [
    "lr_tuned.fit(pd.concat([train_x, valid_x]), pd.concat([train_y, valid_y]))\n",
    "test_acc = accuracy_score(teams_test_target[\"result\"], lr_tuned.predict(test_ft))\n",
    "test_roc_auc = roc_auc_score(teams_test_target[\"result\"], lr_tuned.predict_proba(test_ft)[:, 1])\n",
    "print(f\"Accuracy: {np.mean(test_acc):.4f}, ROC AUC: {np.mean(test_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"n_estimators\": {\"type\": \"int\", \"min\": 100, \"max\": 300},\n",
    "#     \"learning_rate\": {\"type\": \"float\", \"min\": 0.01, \"max\": 0.1}, \n",
    "#     \"max_depth\": {\"type\": \"int\", \"min\": 8, \"max\": 12},\n",
    "#     \"num_leaves\": {\"type\": \"int\", \"min\": 100, \"max\": 150},\n",
    "#     \"min_child_samples\": {\"type\": \"int\", \"min\": 5, \"max\": 15},\n",
    "#     \"subsample\": {\"type\": \"float\", \"min\": 0.5, \"max\": 0.7},\n",
    "#     \"colsample_bytree\": {\"type\": \"float\", \"min\": 0.4, \"max\": 0.6},\n",
    "#     \"reg_alpha\": {\"type\": \"float\", \"min\": 0.001, \"max\": 0.1},\n",
    "#     \"reg_lambda\": {\"type\": \"float\", \"min\": 3.0, \"max\": 6.0},\n",
    "#     \"verbose\": {\"type\": \"int\", \"min\": -1, \"max\": -1}\n",
    "# }\n",
    "\n",
    "# lgbm_tuner = HyperparameterTuner(LGBMClassifier, params, train_x, train_y)\n",
    "# lgbm_tuner.optimize(100)\n",
    "# lgbm_tuner.best_params(), lgbm_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      1060\n",
      "           1       0.76      0.78      0.77      1054\n",
      "\n",
      "    accuracy                           0.77      2114\n",
      "   macro avg       0.77      0.77      0.77      2114\n",
      "weighted avg       0.77      0.77      0.77      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 285,\n",
    "    \"learning_rate\": 0.023007542937157222,\n",
    "    \"max_depth\": 9,\n",
    "    \"num_leaves\": 101,\n",
    "    \"min_child_samples\": 9,\n",
    "    \"subsample\": 0.6754653255644233,\n",
    "    \"colsample_bytree\": 0.5153479009794544,\n",
    "    \"reg_alpha\": 0.07512515626736012,\n",
    "    \"reg_lambda\": 3.3370499751525755,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "lgbm_tuned = LGBMClassifier(**params)\n",
    "lgbm_tuned.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, lgbm_tuned.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7242, ROC AUC: 0.8062\n"
     ]
    }
   ],
   "source": [
    "valid_acc = cross_val_score(lgbm_tuned, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"accuracy\", n_jobs=-1)\n",
    "valid_roc_auc = cross_val_score(lgbm_tuned, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"roc_auc\", n_jobs=-1)\n",
    "print(f\"Accuracy: {np.mean(valid_acc):.4f}, ROC AUC: {np.mean(valid_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7522, ROC AUC: 0.8370\n"
     ]
    }
   ],
   "source": [
    "lgbm_tuned.fit(pd.concat([train_x, valid_x]), pd.concat([train_y, valid_y]))\n",
    "test_acc = accuracy_score(teams_test_target[\"result\"], lgbm_tuned.predict(test_ft))\n",
    "test_roc_auc = roc_auc_score(teams_test_target[\"result\"], lgbm_tuned.predict_proba(test_ft)[:, 1])\n",
    "print(f\"Accuracy: {np.mean(test_acc):.4f}, ROC AUC: {np.mean(test_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"n_estimators\": {\"type\": \"int\", \"min\": 800, \"max\": 1100},\n",
    "#     \"max_depth\": {\"type\": \"int\", \"min\": 15, \"max\": 21},\n",
    "#     \"min_samples_split\": {\"type\": \"int\", \"min\": 15, \"max\": 23},\n",
    "#     \"min_samples_leaf\": {\"type\": \"int\", \"min\": 7, \"max\": 11},\n",
    "#     \"max_features\": {\"type\": \"float\", \"min\": 0.7, \"max\": 0.85},\n",
    "#     \"bootstrap\": {\"type\": \"categorical\", \"values\": [False]},\n",
    "#     \"class_weight\": {\"type\": \"categorical\", \"values\": [\"balanced\"]}\n",
    "# }\n",
    "\n",
    "# rf_tuner = HyperparameterTuner(RandomForestClassifier, params, train_x, train_y)\n",
    "# rf_tuner.optimize(20)\n",
    "# rf_tuner.best_params(), rf_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77      1060\n",
      "           1       0.76      0.78      0.77      1054\n",
      "\n",
      "    accuracy                           0.77      2114\n",
      "   macro avg       0.77      0.77      0.77      2114\n",
      "weighted avg       0.77      0.77      0.77      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 954,\n",
    "    \"max_depth\": 18,\n",
    "    \"min_samples_split\": 19,\n",
    "    \"min_samples_leaf\": 9,\n",
    "    \"max_features\": 0.7814902230628112,\n",
    "    \"bootstrap\": False,\n",
    "    \"class_weight\": \"balanced\",\n",
    "}\n",
    "\n",
    "rf_tuned = RandomForestClassifier(**params)\n",
    "rf_tuned.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, rf_tuned.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7076, ROC AUC: 0.7986\n"
     ]
    }
   ],
   "source": [
    "valid_acc = cross_val_score(rf_tuned, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"accuracy\", n_jobs=-1)\n",
    "valid_roc_auc = cross_val_score(rf_tuned, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"roc_auc\", n_jobs=-1)\n",
    "print(f\"Accuracy: {np.mean(valid_acc):.4f}, ROC AUC: {np.mean(valid_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7466, ROC AUC: 0.8405\n"
     ]
    }
   ],
   "source": [
    "rf_tuned.fit(pd.concat([train_x, valid_x]), pd.concat([train_y, valid_y]))\n",
    "test_acc = accuracy_score(teams_test_target[\"result\"], rf_tuned.predict(test_ft))\n",
    "test_roc_auc = roc_auc_score(teams_test_target[\"result\"], rf_tuned.predict_proba(test_ft)[:, 1])\n",
    "print(f\"Accuracy: {np.mean(test_acc):.4f}, ROC AUC: {np.mean(test_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"learning_rate\": {\"type\": \"float\", \"min\": 0.01, \"max\": 0.1},\n",
    "#     \"max_depth\": {\"type\": \"int\", \"min\": 8, \"max\": 15},\n",
    "#     \"max_iter\": {\"type\": \"int\", \"min\": 100, \"max\": 300},\n",
    "#     \"min_samples_leaf\": {\"type\": \"int\", \"min\": 5, \"max\": 15},\n",
    "#     \"l2_regularization\": {\"type\": \"float\", \"min\": 0.5, \"max\": 3.0},\n",
    "#     \"max_leaf_nodes\": {\"type\": \"int\", \"min\": 40, \"max\": 90}\n",
    "# }\n",
    "\n",
    "# hgbc_tuner = HyperparameterTuner(HistGradientBoostingClassifier, params, train_x, train_y)\n",
    "# hgbc_tuner.optimize(100)\n",
    "# hgbc_tuner.best_params(), hgbc_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78      1060\n",
      "           1       0.78      0.79      0.78      1054\n",
      "\n",
      "    accuracy                           0.78      2114\n",
      "   macro avg       0.78      0.78      0.78      2114\n",
      "weighted avg       0.78      0.78      0.78      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"learning_rate\": 0.022119818280047138,\n",
    "    \"max_depth\": 12,\n",
    "    \"max_iter\": 276,\n",
    "    \"min_samples_leaf\": 5,\n",
    "    \"l2_regularization\": 0.9584267642328501,\n",
    "    \"max_leaf_nodes\": 44,\n",
    "}\n",
    "\n",
    "\n",
    "hgbc_tuned = HistGradientBoostingClassifier(**params)\n",
    "hgbc_tuned.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, hgbc_tuned.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7336, ROC AUC: 0.8195\n"
     ]
    }
   ],
   "source": [
    "valid_acc = cross_val_score(hgbc_tuned, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"accuracy\", n_jobs=-1)\n",
    "valid_roc_auc = cross_val_score(hgbc_tuned, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"roc_auc\", n_jobs=-1)\n",
    "print(f\"Accuracy: {np.mean(valid_acc):.4f}, ROC AUC: {np.mean(valid_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7586, ROC AUC: 0.8497\n"
     ]
    }
   ],
   "source": [
    "hgbc_tuned.fit(pd.concat([train_x, valid_x]), pd.concat([train_y, valid_y]))\n",
    "test_acc = accuracy_score(teams_test_target[\"result\"], hgbc_tuned.predict(test_ft))\n",
    "test_roc_auc = roc_auc_score(teams_test_target[\"result\"], hgbc_tuned.predict_proba(test_ft)[:, 1])\n",
    "print(f\"Accuracy: {np.mean(test_acc):.4f}, ROC AUC: {np.mean(test_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"n_estimators\": {\"type\": \"int\", \"min\": 200, \"max\": 400},\n",
    "#     \"learning_rate\": {\"type\": \"float\", \"min\": 0.1, \"max\": 0.25},\n",
    "#     \"algorithm\": {\"type\": \"categorical\", \"values\": [\"SAMME.R\"]}\n",
    "# }\n",
    "\n",
    "# ada_tuner = HyperparameterTuner(AdaBoostClassifier, params, train_x, train_y)\n",
    "# ada_tuner.optimize(50)\n",
    "# ada_tuner.best_params(), ada_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kwon3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74      1060\n",
      "           1       0.74      0.71      0.73      1054\n",
      "\n",
      "    accuracy                           0.73      2114\n",
      "   macro avg       0.73      0.73      0.73      2114\n",
      "weighted avg       0.73      0.73      0.73      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 358,\n",
    "    \"learning_rate\": 0.13883883597100793,\n",
    "    \"algorithm\": \"SAMME.R\",\n",
    "}\n",
    "\n",
    "\n",
    "ada_tuned = AdaBoostClassifier(**params)\n",
    "ada_tuned.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, ada_tuned.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6674, ROC AUC: 0.7350\n"
     ]
    }
   ],
   "source": [
    "valid_acc = cross_val_score(ada_tuned, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"accuracy\", n_jobs=-1)\n",
    "valid_roc_auc = cross_val_score(ada_tuned, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"roc_auc\", n_jobs=-1)\n",
    "print(f\"Accuracy: {np.mean(valid_acc):.4f}, ROC AUC: {np.mean(valid_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kwon3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6906, ROC AUC: 0.7462\n"
     ]
    }
   ],
   "source": [
    "ada_tuned.fit(pd.concat([train_x, valid_x]), pd.concat([train_y, valid_y]))\n",
    "test_acc = accuracy_score(teams_test_target[\"result\"], ada_tuned.predict(test_ft))\n",
    "test_roc_auc = roc_auc_score(teams_test_target[\"result\"], ada_tuned.predict_proba(test_ft)[:, 1])\n",
    "print(f\"Accuracy: {np.mean(test_acc):.4f}, ROC AUC: {np.mean(test_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"C\": {\"type\": \"float\", \"min\": 0.1, \"max\": 0.5},\n",
    "#     \"kernel\": {\"type\": \"categorical\", \"values\": [\"linear\"]},\n",
    "#     \"degree\": {\"type\": \"int\", \"min\": 3, \"max\": 5},\n",
    "#     \"gamma\": {\"type\": \"float\", \"min\": 0.4, \"max\": 0.9},\n",
    "#     \"coef0\": {\"type\": \"float\", \"min\": 1.5, \"max\": 4.0},\n",
    "#     \"class_weight\": {\"type\": \"categorical\", \"values\": [None]}\n",
    "# }\n",
    "\n",
    "# svc_tuner = HyperparameterTuner(SVC, params, train_x, train_y)\n",
    "# svc_tuner.optimize(100)\n",
    "# svc_tuner.best_params(), svc_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.63      0.67      1060\n",
      "           1       0.67      0.75      0.71      1054\n",
      "\n",
      "    accuracy                           0.69      2114\n",
      "   macro avg       0.69      0.69      0.69      2114\n",
      "weighted avg       0.69      0.69      0.69      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"C\": 0.21950805677161292,\n",
    "    \"kernel\": \"linear\",\n",
    "    \"degree\": 4,\n",
    "    \"gamma\": 0.671045772731431,\n",
    "    \"coef0\": 2.7929809033044726,\n",
    "    \"class_weight\": None,\n",
    "}\n",
    "\n",
    "svc_tuned = SVC(**params, probability=True)\n",
    "svc_tuned.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, svc_tuned.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6659, ROC AUC: 0.7356\n"
     ]
    }
   ],
   "source": [
    "valid_acc = cross_val_score(svc_tuned, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"accuracy\", n_jobs=-1)\n",
    "valid_roc_auc = cross_val_score(svc_tuned, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"roc_auc\", n_jobs=-1)\n",
    "print(f\"Accuracy: {np.mean(valid_acc):.4f}, ROC AUC: {np.mean(valid_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6571, ROC AUC: 0.7199\n"
     ]
    }
   ],
   "source": [
    "svc_tuned.fit(pd.concat([train_x, valid_x]), pd.concat([train_y, valid_y]))\n",
    "test_acc = accuracy_score(teams_test_target[\"result\"], svc_tuned.predict(test_ft))\n",
    "test_roc_auc = roc_auc_score(teams_test_target[\"result\"], svc_tuned.predict_proba(test_ft)[:, 1])\n",
    "print(f\"Accuracy: {np.mean(test_acc):.4f}, ROC AUC: {np.mean(test_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"n_estimators\": {\"type\": \"int\", \"min\": 300, \"max\": 400},\n",
    "#     \"learning_rate\": {\"type\": \"float\", \"min\": 0.005, \"max\": 0.02},\n",
    "#     \"max_depth\": {\"type\": \"int\", \"min\": 4, \"max\": 6},\n",
    "#     \"min_child_weight\": {\"type\": \"int\", \"min\": 2, \"max\": 4},\n",
    "#     \"gamma\": {\"type\": \"float\", \"min\": 0.1, \"max\": 0.4},\n",
    "#     \"subsample\": {\"type\": \"float\", \"min\": 0.8, \"max\": 1.0},\n",
    "#     \"colsample_bytree\": {\"type\": \"float\", \"min\": 0.9, \"max\": 1.0},\n",
    "#     \"reg_alpha\": {\"type\": \"float\", \"min\": 0.05, \"max\": 0.2},\n",
    "#     \"reg_lambda\": {\"type\": \"float\", \"min\": 3.0, \"max\": 4.5}\n",
    "# }\n",
    "\n",
    "# sgb_tuner = HyperparameterTuner(XGBClassifier, params, train_x, train_y)\n",
    "# sgb_tuner.optimize(100)\n",
    "# sgb_tuner.best_params(), sgb_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78      1060\n",
      "           1       0.78      0.80      0.79      1054\n",
      "\n",
      "    accuracy                           0.79      2114\n",
      "   macro avg       0.79      0.79      0.79      2114\n",
      "weighted avg       0.79      0.79      0.79      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 337,\n",
    "    \"learning_rate\": 0.015272630148352066,\n",
    "    \"max_depth\": 5,\n",
    "    \"min_child_weight\": 2,\n",
    "    \"gamma\": 0.24988522273215766,\n",
    "    \"subsample\": 0.9639840429354903,\n",
    "    \"colsample_bytree\": 0.985608479043216,\n",
    "    \"reg_alpha\": 0.1856156681311941,\n",
    "    \"reg_lambda\": 3.4637470458659014,\n",
    "}\n",
    "\n",
    "\n",
    "xgb_tuned = XGBClassifier(**params)\n",
    "xgb_tuned.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, xgb_tuned.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7226, ROC AUC: 0.8065\n"
     ]
    }
   ],
   "source": [
    "valid_acc = cross_val_score(xgb_tuned, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"accuracy\", n_jobs=-1)\n",
    "valid_roc_auc = cross_val_score(xgb_tuned, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"roc_auc\", n_jobs=-1)\n",
    "print(f\"Accuracy: {np.mean(valid_acc):.4f}, ROC AUC: {np.mean(valid_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7371, ROC AUC: 0.8190\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned.fit(pd.concat([train_x, valid_x]), pd.concat([train_y, valid_y]))\n",
    "test_acc = accuracy_score(teams_test_target[\"result\"], xgb_tuned.predict(test_ft))\n",
    "test_roc_auc = roc_auc_score(teams_test_target[\"result\"], xgb_tuned.predict_proba(test_ft)[:, 1])\n",
    "print(f\"Accuracy: {np.mean(test_acc):.4f}, ROC AUC: {np.mean(test_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### category 형식 컬럼이 포함된 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['league',\n",
       " 'teamname',\n",
       " 'opp_teamname',\n",
       " 'ban1',\n",
       " 'ban2',\n",
       " 'ban3',\n",
       " 'ban4',\n",
       " 'ban5',\n",
       " 'pick1',\n",
       " 'pick2',\n",
       " 'pick3',\n",
       " 'pick4',\n",
       " 'pick5']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = cat_train_x.select_dtypes(\"category\").columns.tolist()\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"iterations\": {\"type\": \"int\", \"min\": 300, \"max\": 600},\n",
    "#     \"learning_rate\": {\"type\": \"float\", \"min\": 0.15, \"max\": 0.3},\n",
    "#     \"depth\": {\"type\": \"int\", \"min\": 8, \"max\": 12},\n",
    "#     \"l2_leaf_reg\": {\"type\": \"float\", \"min\": 6.0, \"max\": 10.0},\n",
    "#     \"min_child_samples\": {\"type\": \"int\", \"min\": 8, \"max\": 16},\n",
    "#     \"max_bin\": {\"type\": \"int\", \"min\": 300, \"max\": 400},\n",
    "#     \"verbose\": {\"type\": \"int\", \"min\": 100, \"max\": 100}\n",
    "# }\n",
    "\n",
    "# cat_tuner = HyperparameterTuner(CatBoostClassifier, params, cat_train_x, cat_train_y, cat_features)\n",
    "# cat_tuner.optimize(20)\n",
    "# cat_tuner.best_params(), cat_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6079555\ttotal: 226ms\tremaining: 1m 33s\n",
      "100:\tlearn: 0.1385176\ttotal: 26.5s\tremaining: 1m 21s\n",
      "200:\tlearn: 0.0588177\ttotal: 52.8s\tremaining: 55.7s\n",
      "300:\tlearn: 0.0327123\ttotal: 1m 18s\tremaining: 29.4s\n",
      "400:\tlearn: 0.0213888\ttotal: 1m 46s\tremaining: 3.19s\n",
      "412:\tlearn: 0.0205659\ttotal: 1m 49s\tremaining: 0us\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1060\n",
      "           1       0.79      0.77      0.78      1054\n",
      "\n",
      "    accuracy                           0.78      2114\n",
      "   macro avg       0.78      0.78      0.78      2114\n",
      "weighted avg       0.78      0.78      0.78      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"iterations\": 413,\n",
    "    \"learning_rate\": 0.24110432469185597,\n",
    "    \"depth\": 10,\n",
    "    \"l2_leaf_reg\": 8.905869555950142,\n",
    "    \"min_child_samples\": 12,\n",
    "    \"max_bin\": 342,\n",
    "    \"verbose\": 100,\n",
    "}\n",
    "\n",
    "cat_tuned = CatBoostClassifier(**params, cat_features=cat_features)\n",
    "cat_tuned.fit(cat_train_x, cat_train_y)\n",
    "print(classification_report(cat_valid_y, cat_tuned.predict(cat_valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7070, ROC AUC: 0.7889\n"
     ]
    }
   ],
   "source": [
    "valid_acc = cross_val_score(cat_tuned, cat_train_x, cat_train_y, cv=TimeSeriesSplit(5), scoring=\"accuracy\", n_jobs=-1)\n",
    "valid_roc_auc = cross_val_score(cat_tuned, cat_train_x, cat_train_y, cv=TimeSeriesSplit(5), scoring=\"roc_auc\", n_jobs=-1)\n",
    "print(f\"Accuracy: {np.mean(valid_acc):.4f}, ROC AUC: {np.mean(valid_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6275820\ttotal: 256ms\tremaining: 1m 45s\n",
      "100:\tlearn: 0.1731344\ttotal: 27.5s\tremaining: 1m 25s\n",
      "200:\tlearn: 0.0710989\ttotal: 56.1s\tremaining: 59.2s\n",
      "300:\tlearn: 0.0412594\ttotal: 1m 24s\tremaining: 31.3s\n",
      "400:\tlearn: 0.0271566\ttotal: 1m 51s\tremaining: 3.35s\n",
      "412:\tlearn: 0.0259547\ttotal: 1m 55s\tremaining: 0us\n",
      "Accuracy: 0.7207, ROC AUC: 0.8029\n"
     ]
    }
   ],
   "source": [
    "cat_tuned.fit(pd.concat([cat_train_x, cat_valid_x]), pd.concat([cat_train_y, cat_valid_y]))\n",
    "test_acc = accuracy_score(teams_test_target[\"result\"], cat_tuned.predict(cat_test_ft))\n",
    "test_roc_auc = roc_auc_score(teams_test_target[\"result\"], cat_tuned.predict_proba(cat_test_ft)[:, 1])\n",
    "print(f\"Accuracy: {np.mean(test_acc):.4f}, ROC AUC: {np.mean(test_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned_models = {\n",
    "#     'lr': lr_final,\n",
    "#     'lgbm': lgbm_final,\n",
    "#     'rf': rf_final,\n",
    "#     'hgbc': hgbc_final,\n",
    "#     'ada': ada_final,\n",
    "#     'svc': svc_final,\n",
    "#     'xgb': xgb_final,\n",
    "#     'cat': cat_final\n",
    "# }\n",
    "\n",
    "# with init_wandb_run(\"feature_comparison\") as run:\n",
    "#     run.config.update({\n",
    "#         \"features\": {\n",
    "#             \"tuned\": {\n",
    "#                 \"count\": train_ft.shape[1],\n",
    "#                 \"list\": train_ft.columns.tolist()\n",
    "#             }\n",
    "#         },\n",
    "#         \"models\": list(tuned_models.keys())\n",
    "#     })\n",
    "    \n",
    "#     log_model_performance_by_features(\n",
    "#         \"tuned\",\n",
    "#         tuned_models,\n",
    "#         train_x,\n",
    "#         valid_x,\n",
    "#         test_ft,\n",
    "#         train_y,\n",
    "#         valid_y,\n",
    "#         teams_test_target[\"result\"],\n",
    "#         cat_train_x,\n",
    "#         cat_valid_x,\n",
    "#         cat_test_ft\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78      1060\n",
      "           1       0.78      0.79      0.78      1054\n",
      "\n",
      "    accuracy                           0.78      2114\n",
      "   macro avg       0.78      0.78      0.78      2114\n",
      "weighted avg       0.78      0.78      0.78      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [\n",
    "    # (\"lr\", lr_tuned),\n",
    "    (\"lgbm\", lgbm_tuned),\n",
    "    (\"rf\", rf_tuned),\n",
    "    (\"hgbc\", hgbc_tuned),\n",
    "    # (\"ada\", ada_tuned),\n",
    "    # (\"svc\", svc_tuned),\n",
    "    (\"xgb\", xgb_tuned),\n",
    "]\n",
    "\n",
    "final_estimator = LogisticRegression(random_state=SEED)\n",
    "stacking_clf = StackingClassifier(estimators, final_estimator)\n",
    "stacking_clf.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, stacking_clf.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7355, ROC AUC: 0.8198\n"
     ]
    }
   ],
   "source": [
    "valid_acc = cross_val_score(stacking_clf, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"accuracy\", n_jobs=-1)\n",
    "valid_roc_auc = cross_val_score(stacking_clf, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"roc_auc\", n_jobs=-1)\n",
    "print(f\"Accuracy: {np.mean(valid_acc):.4f}, ROC AUC: {np.mean(valid_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7539, ROC AUC: 0.8505\n"
     ]
    }
   ],
   "source": [
    "stacking_clf.fit(pd.concat([train_x, valid_x]), pd.concat([train_y, valid_y]))\n",
    "test_acc = accuracy_score(teams_test_target[\"result\"], stacking_clf.predict(test_ft))\n",
    "test_roc_auc = roc_auc_score(teams_test_target[\"result\"], stacking_clf.predict_proba(test_ft)[:, 1])\n",
    "print(f\"Accuracy: {np.mean(test_acc):.4f}, ROC AUC: {np.mean(test_roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- StackingClassifier + CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 검증셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6079555\ttotal: 207ms\tremaining: 1m 25s\n",
      "100:\tlearn: 0.1385176\ttotal: 23.4s\tremaining: 1m 12s\n",
      "200:\tlearn: 0.0588177\ttotal: 46.9s\tremaining: 49.5s\n",
      "300:\tlearn: 0.0327123\ttotal: 1m 10s\tremaining: 26.2s\n",
      "400:\tlearn: 0.0213888\ttotal: 1m 34s\tremaining: 2.82s\n",
      "412:\tlearn: 0.0205659\ttotal: 1m 36s\tremaining: 0us\n",
      "Accuracy: 0.7961, ROC AUC: 0.8907\n"
     ]
    }
   ],
   "source": [
    "stacking_clf.fit(train_x, train_y)\n",
    "cat_tuned.fit(cat_train_x, cat_train_y)\n",
    "\n",
    "stacking_test_proba = stacking_clf.predict_proba(valid_x)[:, 1]\n",
    "cat_test_proba = cat_tuned.predict_proba(cat_valid_x)[:, 1]\n",
    "\n",
    "combined_proba = np.mean([stacking_test_proba, cat_test_proba], axis=0)\n",
    "acc = accuracy_score(valid_y, (combined_proba >= 0.5).astype(int))\n",
    "roc_auc = roc_auc_score(valid_y, combined_proba)\n",
    "print(f\"Accuracy: {acc:.4f}, ROC AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_valid_proba = pd.DataFrame({'gameid': valid_df['gameid'], \"teamname\": valid_df['teamname'], 'win_pred': combined_proba})\n",
    "pred_valid_proba.to_csv('output/ensemble_pred_valid.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테스트셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6275820\ttotal: 312ms\tremaining: 2m 8s\n",
      "100:\tlearn: 0.1691727\ttotal: 36s\tremaining: 1m 51s\n",
      "200:\tlearn: 0.0750971\ttotal: 1m 10s\tremaining: 1m 14s\n",
      "300:\tlearn: 0.0393156\ttotal: 1m 45s\tremaining: 39.2s\n",
      "400:\tlearn: 0.0253351\ttotal: 2m 20s\tremaining: 4.2s\n",
      "412:\tlearn: 0.0243252\ttotal: 2m 24s\tremaining: 0us\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1160\n",
      "           1       0.76      0.74      0.75      1164\n",
      "\n",
      "    accuracy                           0.76      2324\n",
      "   macro avg       0.76      0.76      0.76      2324\n",
      "weighted avg       0.76      0.76      0.76      2324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_ft = train_ft[train_x.columns]\n",
    "test_ft = test_ft[train_x.columns]\n",
    "cat_train_ft = cat_train_ft[cat_train_x.columns]\n",
    "cat_test_ft = cat_test_ft[cat_train_x.columns]\n",
    "\n",
    "stacking_clf.fit(train_ft, teams_train_target[\"result\"])\n",
    "cat_tuned.fit(cat_train_ft, teams_train_target[\"result\"])\n",
    "\n",
    "stacking_test_proba = stacking_clf.predict_proba(test_ft)[:, 1]\n",
    "cat_test_proba = cat_tuned.predict_proba(cat_test_ft)[:, 1]\n",
    "\n",
    "final_test_proba = np.mean([stacking_test_proba, cat_test_proba], axis=0)\n",
    "final_test_pred = (final_test_proba >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(teams_test_target[\"result\"], final_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7556, ROC AUC: 0.8422\n"
     ]
    }
   ],
   "source": [
    "test_acc = accuracy_score(teams_test_target[\"result\"], final_test_pred)\n",
    "test_roc_auc = roc_auc_score(teams_test_target[\"result\"], final_test_proba)\n",
    "print(f\"Accuracy: {test_acc:.4f}, ROC AUC: {test_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_proba = pd.DataFrame({'gameid': teams_test_target['gameid'], \"teamname\": teams_test_target['teamname'], 'win_pred': final_test_proba})\n",
    "pred_test_proba.to_csv('output/ensemble_pred_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최종 예측 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6154152\ttotal: 291ms\tremaining: 1m 59s\n",
      "100:\tlearn: 0.1750981\ttotal: 35.4s\tremaining: 1m 49s\n",
      "200:\tlearn: 0.0849220\ttotal: 1m 9s\tremaining: 1m 13s\n",
      "300:\tlearn: 0.0483373\ttotal: 1m 43s\tremaining: 38.5s\n",
      "400:\tlearn: 0.0301632\ttotal: 2m 16s\tremaining: 4.09s\n",
      "412:\tlearn: 0.0288545\ttotal: 2m 20s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.concat([train_ft, test_ft], ignore_index=True)\n",
    "cat_train_data = pd.concat([cat_train_ft, cat_test_ft], ignore_index=True)\n",
    "target_data = pd.concat([teams_train_target, teams_test_target], ignore_index=True)\n",
    "\n",
    "stacking_clf.fit(train_data, target_data[\"result\"])\n",
    "cat_tuned.fit(cat_train_data, target_data[\"result\"])\n",
    "\n",
    "joblib.dump(stacking_clf, \"output/stacking_0107.pkl\")\n",
    "cat_tuned.save_model(\"output/cat_0107.cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"output/cat_features.json\", \"w\") as f:\n",
    "    json.dump(cat_features, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
