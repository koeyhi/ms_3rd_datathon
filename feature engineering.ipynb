{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 111), (2324, 111), (9913, 3), (2324, 3))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = \"LoLesports_data/\"\n",
    "SEED = 42\n",
    "\n",
    "teams_train = pd.read_csv(f\"{DATA_PATH}teams_train.csv\")\n",
    "teams_test = pd.read_csv(f\"{DATA_PATH}teams_test.csv\")\n",
    "\n",
    "teams_train_target = pd.read_csv(f\"{DATA_PATH}teams_train_target.csv\")\n",
    "teams_test_target = pd.read_csv(f\"{DATA_PATH}teams_test_target.csv\")\n",
    "\n",
    "teams_train.shape, teams_test.shape, teams_train_target.shape, teams_test_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 컬럼 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상대 팀 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_opp_teams = teams_train.groupby(\"gameid\")[\"teamname\"].transform(lambda x: x.iloc[::-1].values).to_frame(\"opp_teamname\")\n",
    "teams_train = pd.concat([teams_train, temp_opp_teams], axis=1)\n",
    "temp_opp_teams = teams_test.groupby(\"gameid\")[\"teamname\"].transform(lambda x: x.iloc[::-1].values).to_frame(\"opp_teamname\")\n",
    "teams_test = pd.concat([teams_test, temp_opp_teams], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 날짜 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_train[\"date\"] = pd.to_datetime(teams_train[\"date\"])\n",
    "teams_test[\"date\"] = pd.to_datetime(teams_test[\"date\"])\n",
    "\n",
    "teams_train[\"year\"] = teams_train[\"date\"].dt.year\n",
    "teams_train[\"month\"] = teams_train[\"date\"].dt.month\n",
    "teams_train[\"day\"] = teams_train[\"date\"].dt.day\n",
    "teams_train[\"hour\"] = teams_train[\"date\"].dt.hour\n",
    "teams_train[\"minute\"] = teams_train[\"date\"].dt.minute\n",
    "\n",
    "teams_test[\"year\"] = teams_test[\"date\"].dt.year\n",
    "teams_test[\"month\"] = teams_test[\"date\"].dt.month\n",
    "teams_test[\"day\"] = teams_test[\"date\"].dt.day\n",
    "teams_test[\"hour\"] = teams_test[\"date\"].dt.hour\n",
    "teams_test[\"minute\"] = teams_test[\"date\"].dt.minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 타입 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"league\", \"split\", \"teamname\", \"opp_teamname\", \"ban1\", \"ban2\", \"ban3\", \"ban4\", \"ban5\", \"pick1\", \"pick2\", \"pick3\", \"pick4\", \"pick5\"]\n",
    "\n",
    "teams_train[cols] = teams_train[cols].astype(\"category\")\n",
    "teams_test[cols] = teams_test[cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 특성 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df에 포함되어 있는 특성을 이용한 토대 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 21), (2324, 21))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_game_features = [\n",
    "    \"gameid\",\n",
    "    \"patch\",\n",
    "    \"side\",\n",
    "    \"league\",\n",
    "    \"teamname\",\n",
    "    \"opp_teamname\",\n",
    "    \"ban1\",\n",
    "    \"ban2\",\n",
    "    \"ban3\",\n",
    "    \"ban4\",\n",
    "    \"ban5\",\n",
    "    \"pick1\",\n",
    "    \"pick2\",\n",
    "    \"pick3\",\n",
    "    \"pick4\",\n",
    "    \"pick5\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"day\",\n",
    "    \"hour\",\n",
    "    \"minute\",\n",
    "]\n",
    "\n",
    "train_ft = teams_train[pre_game_features]\n",
    "test_ft = teams_test[pre_game_features]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 팀별 최근 10경기 지표 계산, 상대팀 최근 10경기 지표 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_columns = [\n",
    "    \"result\",\n",
    "    \"gamelength\",\n",
    "    \"kills\",\n",
    "    \"deaths\",\n",
    "    \"assists\",\n",
    "    \"firstblood\",\n",
    "    \"team kpm\",\n",
    "    \"ckpm\",\n",
    "    \"firstdragon\",\n",
    "    \"firstherald\",\n",
    "    \"void_grubs\",\n",
    "    \"firstbaron\",\n",
    "    \"firsttower\",\n",
    "    \"towers\",\n",
    "    \"firstmidtower\",\n",
    "    \"firsttothreetowers\",\n",
    "    \"turretplates\",\n",
    "    \"inhibitors\",\n",
    "    \"damagetochampions\",\n",
    "    \"dpm\",\n",
    "    \"damagetakenperminute\",\n",
    "    \"damagemitigatedperminute\",\n",
    "    \"wardsplaced\",\n",
    "    \"wpm\",\n",
    "    \"wardskilled\",\n",
    "    \"wcpm\",\n",
    "    \"controlwardsbought\",\n",
    "    \"visionscore\",\n",
    "    \"vspm\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 79), (2324, 79))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 팀별 최근 승률 계산을 위한 데이터 정렬\n",
    "temp_train = teams_train.sort_values([\"teamname\", \"year\", \"month\", \"day\", \"hour\", \"minute\"]).reset_index(drop=True)\n",
    "temp_test = teams_test.sort_values([\"teamname\", \"year\", \"month\", \"day\", \"hour\", \"minute\"]).reset_index(drop=True)\n",
    "\n",
    "# 팀별 최근 10경기 평균 계산\n",
    "for col in stats_columns:\n",
    "    # 승률 계산\n",
    "    recent10_train = temp_train.groupby(\"teamname\", observed=True)[col].transform(\n",
    "        lambda x: x.rolling(window=10, min_periods=1).mean().shift(1)\n",
    "    )\n",
    "    train_ft = train_ft.assign(**{f\"recent10_{col}\": recent10_train})\n",
    "\n",
    "    # 테스트 데이터의 지표 계산을 위해 훈련 데이터와 테스트 데이터 결합\n",
    "    combined_data = pd.concat([temp_train, temp_test], ignore_index=True).sort_values(\n",
    "        [\"teamname\", \"year\", \"month\", \"day\", \"hour\", \"minute\"]\n",
    "    )\n",
    "    recent10_combined = combined_data.groupby(\"teamname\", observed=True)[col].transform(\n",
    "        lambda x: x.rolling(window=10, min_periods=1).mean().shift(1)\n",
    "    )\n",
    "    combined_data = combined_data.assign(**{f\"recent10_{col}\": recent10_combined})\n",
    "\n",
    "    # 테스트 데이터의 지표 업데이트\n",
    "    recent10_test = combined_data.tail(len(temp_test))[f\"recent10_{col}\"].values\n",
    "    test_ft = test_ft.assign(**{f\"recent10_{col}\": recent10_test})\n",
    "\n",
    "    # 상대팀 최근 지표 계산\n",
    "    merged_train = train_ft.merge(\n",
    "        train_ft[[\"teamname\", \"year\", \"month\", \"day\", \"hour\", \"minute\", f\"recent10_{col}\"]],\n",
    "        left_on=[\"opp_teamname\", \"year\", \"month\", \"day\", \"hour\", \"minute\"],\n",
    "        right_on=[\"teamname\", \"year\", \"month\", \"day\", \"hour\", \"minute\"],\n",
    "        suffixes=(\"\", \"_opp\"),\n",
    "    )\n",
    "    train_ft = train_ft.assign(\n",
    "        **{f\"opp_recent10_{col}\": merged_train[f\"recent10_{col}_opp\"]}\n",
    "    )\n",
    "\n",
    "    merged_test = test_ft.merge(\n",
    "        combined_data[[\"teamname\", \"year\", \"month\", \"day\", \"hour\", \"minute\", f\"recent10_{col}\"]],\n",
    "        left_on=[\"opp_teamname\", \"year\", \"month\", \"day\", \"hour\", \"minute\"],\n",
    "        right_on=[\"teamname\", \"year\", \"month\", \"day\", \"hour\", \"minute\"],\n",
    "        suffixes=(\"\", \"_opp\"),\n",
    "    )\n",
    "    test_ft = test_ft.assign(\n",
    "        **{f\"opp_recent10_{col}\": merged_test[f\"recent10_{col}_opp\"]}\n",
    "    )\n",
    "\n",
    "    # NaN값 처리 (첫 경기인 경우)\n",
    "    default_value = 0.5 if col == \"result\" else 0\n",
    "    train_ft = train_ft.assign(\n",
    "        **{\n",
    "            f\"recent10_{col}\": train_ft[f\"recent10_{col}\"].fillna(default_value),\n",
    "            f\"opp_recent10_{col}\": train_ft[f\"opp_recent10_{col}\"].fillna(\n",
    "                default_value\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "    test_ft = test_ft.assign(\n",
    "        **{\n",
    "            f\"recent10_{col}\": test_ft[f\"recent10_{col}\"].fillna(default_value),\n",
    "            f\"opp_recent10_{col}\": test_ft[f\"opp_recent10_{col}\"].fillna(default_value),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 특성 리스트에 새로운 지표 추가\n",
    "    pre_game_features.extend([f\"recent10_{col}\", f\"opp_recent10_{col}\"])\n",
    "\n",
    "# 입력 데이터 업데이트\n",
    "train_ft = train_ft[pre_game_features]\n",
    "test_ft = test_ft[pre_game_features]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상대 전적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 80), (2324, 80))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 팀별 맞대결 기록을 시간순으로 계산\n",
    "h2h_records = {}\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 결합 후 시간순 정렬\n",
    "combined_data = pd.concat([teams_train, teams_test], ignore_index=True)\n",
    "combined_data = combined_data.sort_values(['year', 'month', 'day', 'hour', 'minute'])\n",
    "\n",
    "# 각 경기마다 이전 맞대결 기록 계산\n",
    "h2h_winrates = []\n",
    "\n",
    "for idx, match in combined_data.iterrows():\n",
    "    team1, team2 = match['teamname'], match['opp_teamname']\n",
    "    year = match['year']\n",
    "    key = (team1, team2, year)\n",
    "    \n",
    "    # 현재 시점까지의 맞대결 기록 저장\n",
    "    if key not in h2h_records:\n",
    "        h2h_records[key] = {'wins': 0, 'total': 0}\n",
    "        h2h_winrates.append(0.5)  # 첫 맞대결인 경우 0.5 반환\n",
    "    else:\n",
    "        record = h2h_records[key]\n",
    "        h2h_winrates.append(record['wins'] / record['total'] if record['total'] > 0 else 0.5)\n",
    "    \n",
    "    # 현재 경기 결과 반영\n",
    "    result = match['result']\n",
    "    h2h_records[key]['total'] += 1\n",
    "    if result == 1:\n",
    "        h2h_records[key]['wins'] += 1\n",
    "        \n",
    "    # 상대팀 관점의 기록도 업데이트\n",
    "    key_reverse = (team2, team1, year)\n",
    "    if key_reverse not in h2h_records:\n",
    "        h2h_records[key_reverse] = {'wins': 0, 'total': 0}\n",
    "    h2h_records[key_reverse]['total'] += 1\n",
    "    if result == 0:\n",
    "        h2h_records[key_reverse]['wins'] += 1\n",
    "\n",
    "# 계산된 승률을 훈련/테스트 데이터에 할당\n",
    "train_ft['h2h_winrate'] = h2h_winrates[:len(teams_train)]\n",
    "test_ft['h2h_winrate'] = h2h_winrates[len(teams_train):]\n",
    "\n",
    "# 특성 리스트에 h2h_winrate 추가\n",
    "pre_game_features.append('h2h_winrate')\n",
    "\n",
    "# 입력 데이터 업데이트\n",
    "train_ft = train_ft[pre_game_features]\n",
    "test_ft = test_ft[pre_game_features]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 팀의 리그별 승률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 81), (2324, 81))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 팀별 리그 승률 기록을 저장할 딕셔너리\n",
    "league_records = {}\n",
    "league_winrates = []\n",
    "\n",
    "# 날짜순으로 정렬\n",
    "combined_data = pd.concat([teams_train, teams_test], ignore_index=True)\n",
    "combined_data = combined_data.sort_values(['year', 'month', 'day', 'hour', 'minute'])\n",
    "\n",
    "# 훈련 데이터에서 팀별 리그 승률 계산\n",
    "for idx, match in combined_data.iterrows():\n",
    "    team = match['teamname']\n",
    "    league = match['league']\n",
    "    year = match['year']\n",
    "    key = (team, league, year)\n",
    "    \n",
    "    # 현재 시점까지의 리그 승률 계산\n",
    "    if key not in league_records:\n",
    "        league_records[key] = {'wins': 0, 'total': 0}\n",
    "        league_winrates.append(0.5)  # 첫 경기인 경우 0.5 반환\n",
    "    else:\n",
    "        record = league_records[key]\n",
    "        league_winrates.append(record['wins'] / record['total'] if record['total'] > 0 else 0.5)\n",
    "    \n",
    "    # 현재 경기 결과 반영\n",
    "    result = match['result']\n",
    "    league_records[key]['total'] += 1\n",
    "    if result == 1:\n",
    "        league_records[key]['wins'] += 1\n",
    "\n",
    "# 계산된 승률을 훈련/테스트 데이터에 할당\n",
    "train_ft['league_winrate'] = league_winrates[:len(teams_train)]\n",
    "test_ft['league_winrate'] = league_winrates[len(teams_train):]\n",
    "\n",
    "# 특성 리스트에 league_winrate 추가\n",
    "pre_game_features.append('league_winrate')\n",
    "\n",
    "# 입력 데이터 업데이트\n",
    "train_ft = train_ft[pre_game_features]\n",
    "test_ft = test_ft[pre_game_features]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft[\"side\"] = train_ft[\"side\"].map({\"Blue\": 0, \"Red\": 1}) # 진영 인코딩\n",
    "test_ft[\"side\"] = test_ft[\"side\"].map({\"Blue\": 0, \"Red\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft.to_csv(\"LoLesports_data/featured_train.csv\", index=False)\n",
    "test_ft.to_csv(\"LoLesports_data/featured_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train_ft = train_ft.copy()\n",
    "cat_test_ft = test_ft.copy()\n",
    "cat_pre_game_features = pre_game_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def preprocess(train_ft, test_ft):\n",
    "    champion_columns_teams = ['ban1', 'ban2', 'ban3', 'ban4', 'ban5', 'pick1', 'pick2', 'pick3', 'pick4', 'pick5'] # 챔피언 레이블인코딩\n",
    "\n",
    "    champions = pd.concat([\n",
    "        train_ft[champion_columns_teams],\n",
    "        test_ft[champion_columns_teams],\n",
    "    ]).stack().unique()\n",
    "\n",
    "    champions_df = pd.DataFrame({'champion': champions})\n",
    "    champions_df = champions_df.dropna().reset_index(drop=True)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    champions_df['champion_encoded'] = le.fit_transform(champions_df['champion'])\n",
    "\n",
    "    for col in champion_columns_teams:\n",
    "        train_ft[col] = le.transform(train_ft[col])\n",
    "        test_ft[col] = le.transform(test_ft[col])\n",
    "        \n",
    "    encoder = OneHotEncoder() # 리그 원핫인코딩\n",
    "    league_encoded = encoder.fit_transform(train_ft[[\"league\"]]).toarray()\n",
    "    pre_game_features.extend(encoder.get_feature_names_out())\n",
    "    league_cols = [f\"league_{col}\" for col in encoder.categories_[0]]\n",
    "    train_ft = pd.concat(\n",
    "        [train_ft, pd.DataFrame(league_encoded, columns=league_cols)], axis=1\n",
    "    )\n",
    "    train_ft.drop(\"league\", axis=1, inplace=True)\n",
    "\n",
    "    league_encoded = encoder.transform(test_ft[[\"league\"]]).toarray()\n",
    "    test_ft = pd.concat(\n",
    "        [test_ft, pd.DataFrame(league_encoded, columns=league_cols)], axis=1\n",
    "    )\n",
    "    test_ft.drop(\"league\", axis=1, inplace=True)\n",
    "\n",
    "    le_team = LabelEncoder()\n",
    "    all_team_names = pd.concat(\n",
    "        [\n",
    "            train_ft[\"teamname\"],\n",
    "            test_ft[\"teamname\"],\n",
    "            train_ft[\"opp_teamname\"],\n",
    "            test_ft[\"opp_teamname\"],\n",
    "        ]\n",
    "    )\n",
    "    le_team.fit(all_team_names)\n",
    "\n",
    "    train_ft[\"teamname\"] = le_team.transform(train_ft[\"teamname\"])\n",
    "    train_ft[\"opp_teamname\"] = le_team.transform(train_ft[\"opp_teamname\"])\n",
    "\n",
    "    test_ft[\"teamname\"] = le_team.transform(test_ft[\"teamname\"])\n",
    "    test_ft[\"opp_teamname\"] = le_team.transform(test_ft[\"opp_teamname\"])\n",
    "    \n",
    "    return train_ft, test_ft\n",
    "\n",
    "train_ft, test_ft = preprocess(train_ft, test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['gameid'], dtype='object'), Index(['gameid'], dtype='object'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.select_dtypes(\"object\").columns, test_ft.select_dtypes(\"object\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 88), (2324, 88), (9913, 81), (2324, 81))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "def scale(train_ft, test_ft):\n",
    "    train_ft[train_ft.select_dtypes(\"number\").columns] = scaler.fit_transform(\n",
    "        train_ft[train_ft.select_dtypes(\"number\").columns]\n",
    "    )\n",
    "    test_ft[test_ft.select_dtypes(\"number\").columns] = scaler.transform(\n",
    "        test_ft[test_ft.select_dtypes(\"number\").columns]\n",
    "    )\n",
    "    return train_ft, test_ft\n",
    "\n",
    "\n",
    "train_ft, test_ft = scale(train_ft, test_ft)\n",
    "cat_train_ft, cat_test_ft = scale(cat_train_ft, cat_test_ft)\n",
    "\n",
    "train_ft.shape, test_ft.shape, cat_train_ft.shape, cat_test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습 및 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하이퍼파라미터 튜닝 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "\n",
    "class HyperparameterTuner:\n",
    "    def __init__(self, model, params, train, target, cat_features=None):\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "        self.train = train\n",
    "        self.target = target\n",
    "        self.cat_features = cat_features\n",
    "        self.cv = TimeSeriesSplit(n_splits=5)\n",
    "        self.study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "    def objective(self, trial):\n",
    "        params = {}\n",
    "        \n",
    "        for param_name, param_range in self.params.items():\n",
    "            if param_range[\"type\"] == \"int\":\n",
    "                params[param_name] = trial.suggest_int(\n",
    "                    param_name, param_range[\"min\"], param_range[\"max\"]\n",
    "                )\n",
    "            elif param_range[\"type\"] == \"float\":\n",
    "                params[param_name] = trial.suggest_float(\n",
    "                    param_name, param_range[\"min\"], param_range[\"max\"]\n",
    "                )\n",
    "            elif param_range[\"type\"] == \"categorical\":\n",
    "                params[param_name] = trial.suggest_categorical(\n",
    "                    param_name, param_range[\"values\"]\n",
    "                )\n",
    "        if self.model == CatBoostClassifier:\n",
    "            model = self.model(**params, cat_features=self.cat_features)\n",
    "        else:\n",
    "            model = self.model(**params)\n",
    "\n",
    "        model.fit(self.train, self.target)\n",
    "            \n",
    "        scores = cross_val_score(\n",
    "            model, self.train, self.target, cv=self.cv, scoring=\"accuracy\", n_jobs=-1\n",
    "        ).mean()\n",
    "        return scores\n",
    "\n",
    "    def optimize(self, n_trials):\n",
    "        self.study.optimize(self.objective, n_trials=n_trials)\n",
    "\n",
    "    def best_params(self):\n",
    "        return self.study.best_params\n",
    "\n",
    "    def best_score(self):\n",
    "        return self.study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모든 컬럼 형식이 number인 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7799, 87), (2114, 87))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_game_features.remove(\"league\")\n",
    "\n",
    "cutoff_patch = train_ft[\"patch\"].quantile(0.8)\n",
    "train_games = train_ft[train_ft[\"patch\"] < cutoff_patch][\"gameid\"].unique()\n",
    "valid_games = train_ft[train_ft[\"patch\"] >= cutoff_patch][\"gameid\"].unique()\n",
    "\n",
    "train_x = train_ft[train_ft[\"gameid\"].isin(train_games)][pre_game_features]\n",
    "valid_x = train_ft[train_ft[\"gameid\"].isin(valid_games)][pre_game_features]\n",
    "\n",
    "train_y = teams_train_target[teams_train_target[\"gameid\"].isin(train_games)][\"result\"]\n",
    "valid_y = teams_train_target[teams_train_target[\"gameid\"].isin(valid_games)][\"result\"]\n",
    "\n",
    "train_x.drop(columns=[\"gameid\"], inplace=True)\n",
    "valid_x.drop(columns=[\"gameid\"], inplace=True)\n",
    "\n",
    "train_x.shape, valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression : 0.6666666666666667, 0.02602866877167562\n",
      "LGBMClassifier : 0.7237875288683603, 0.03853238745277667\n",
      "RandomForestClassifier : 0.6592763664357199, 0.03672821942421046\n",
      "HistGradientBoostingClassifier : 0.7131639722863741, 0.04398000548968287\n",
      "AdaBoostClassifier : 0.6662047729022325, 0.03532338246790577\n",
      "SVC : 0.6649730561970746, 0.026342796615792145\n",
      "XGBClassifier : 0.7148575827559661, 0.035730401119286326\n",
      "CatBoostClassifier : 0.7122401847575057, 0.036312149083314385\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    LogisticRegression(random_state=SEED),\n",
    "    LGBMClassifier(random_state=SEED, n_jobs=-1),\n",
    "    RandomForestClassifier(random_state=SEED, n_jobs=-1),\n",
    "    HistGradientBoostingClassifier(random_state=SEED),\n",
    "    AdaBoostClassifier(random_state=SEED),\n",
    "    SVC(random_state=SEED),\n",
    "    XGBClassifier(random_state=SEED, n_jobs=-1),\n",
    "    CatBoostClassifier(random_state=SEED, verbose=0),\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    scores = cross_val_score(model, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"accuracy\", n_jobs=-1)\n",
    "    print(f\"{model.__class__.__name__} : {np.mean(scores)}, {np.std(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"C\": {\"type\": \"float\", \"min\": 0.01, \"max\": 10},\n",
    "#     \"penalty\": {\"type\": \"categorical\", \"values\": [\"l1\", \"l2\"]},\n",
    "#     \"solver\": {\"type\": \"categorical\", \"values\": [\"liblinear\", \"saga\"]},\n",
    "#     \"max_iter\": {\"type\": \"int\", \"min\": 100, \"max\": 2000},\n",
    "# }\n",
    "\n",
    "# lr_vt_tuner = HyperparameterTuner(LogisticRegression, params, train_x, train_y)\n",
    "# lr_vt_tuner.optimize(100)\n",
    "# lr_vt_tuner.best_params(), lr_vt_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68      1060\n",
      "           1       0.67      0.73      0.70      1054\n",
      "\n",
      "    accuracy                           0.69      2114\n",
      "   macro avg       0.69      0.69      0.69      2114\n",
      "weighted avg       0.69      0.69      0.69      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"C\": 0.38414964961856957,\n",
    "    \"penalty\": \"l1\",\n",
    "    \"solver\": \"liblinear\",\n",
    "    \"max_iter\": 1903\n",
    "}\n",
    "\n",
    "lr_final = LogisticRegression(**params)\n",
    "lr_final.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, lr_final.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7789740789803444"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(valid_y, lr_final.predict_proba(valid_x)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"n_estimators\": {\"type\": \"int\", \"min\": 100, \"max\": 300},\n",
    "#     \"learning_rate\": {\"type\": \"float\", \"min\": 0.01, \"max\": 0.1}, \n",
    "#     \"max_depth\": {\"type\": \"int\", \"min\": 8, \"max\": 12},\n",
    "#     \"num_leaves\": {\"type\": \"int\", \"min\": 100, \"max\": 150},\n",
    "#     \"min_child_samples\": {\"type\": \"int\", \"min\": 5, \"max\": 15},\n",
    "#     \"subsample\": {\"type\": \"float\", \"min\": 0.5, \"max\": 0.7},\n",
    "#     \"colsample_bytree\": {\"type\": \"float\", \"min\": 0.4, \"max\": 0.6},\n",
    "#     \"reg_alpha\": {\"type\": \"float\", \"min\": 0.001, \"max\": 0.1},\n",
    "#     \"reg_lambda\": {\"type\": \"float\", \"min\": 3.0, \"max\": 6.0},\n",
    "#     \"verbose\": {\"type\": \"int\", \"min\": -1, \"max\": -1}\n",
    "# }\n",
    "\n",
    "# lgbm_tuner = HyperparameterTuner(LGBMClassifier, params, train_x, train_y)\n",
    "# lgbm_tuner.optimize(100)\n",
    "# lgbm_tuner.best_params(), lgbm_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      1060\n",
      "           1       0.76      0.78      0.77      1054\n",
      "\n",
      "    accuracy                           0.77      2114\n",
      "   macro avg       0.77      0.77      0.77      2114\n",
      "weighted avg       0.77      0.77      0.77      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 285,\n",
    "    \"learning_rate\": 0.023007542937157222,\n",
    "    \"max_depth\": 9,\n",
    "    \"num_leaves\": 101,\n",
    "    \"min_child_samples\": 9,\n",
    "    \"subsample\": 0.6754653255644233,\n",
    "    \"colsample_bytree\": 0.5153479009794544,\n",
    "    \"reg_alpha\": 0.07512515626736012,\n",
    "    \"reg_lambda\": 3.3370499751525755,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "lgbm_final = LGBMClassifier(**params)\n",
    "lgbm_final.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, lgbm_final.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8747520675951451"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(valid_y, lgbm_final.predict_proba(valid_x)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"n_estimators\": {\"type\": \"int\", \"min\": 800, \"max\": 1100},\n",
    "#     \"max_depth\": {\"type\": \"int\", \"min\": 15, \"max\": 21},\n",
    "#     \"min_samples_split\": {\"type\": \"int\", \"min\": 15, \"max\": 23},\n",
    "#     \"min_samples_leaf\": {\"type\": \"int\", \"min\": 7, \"max\": 11},\n",
    "#     \"max_features\": {\"type\": \"float\", \"min\": 0.7, \"max\": 0.85},\n",
    "#     \"bootstrap\": {\"type\": \"categorical\", \"values\": [False]},\n",
    "#     \"class_weight\": {\"type\": \"categorical\", \"values\": [\"balanced\"]}\n",
    "# }\n",
    "\n",
    "# rf_tuner = HyperparameterTuner(RandomForestClassifier, params, train_x, train_y)\n",
    "# rf_tuner.optimize(20)\n",
    "# rf_tuner.best_params(), rf_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      1060\n",
      "           1       0.76      0.78      0.77      1054\n",
      "\n",
      "    accuracy                           0.77      2114\n",
      "   macro avg       0.77      0.77      0.77      2114\n",
      "weighted avg       0.77      0.77      0.77      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 954,\n",
    "    \"max_depth\": 18,\n",
    "    \"min_samples_split\": 19,\n",
    "    \"min_samples_leaf\": 9,\n",
    "    \"max_features\": 0.7814902230628112,\n",
    "    \"bootstrap\": False,\n",
    "    \"class_weight\": \"balanced\",\n",
    "}\n",
    "\n",
    "rf_final = RandomForestClassifier(**params)\n",
    "rf_final.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, rf_final.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8731373742436719"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(valid_y, rf_final.predict_proba(valid_x)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"learning_rate\": {\"type\": \"float\", \"min\": 0.01, \"max\": 0.1},\n",
    "#     \"max_depth\": {\"type\": \"int\", \"min\": 8, \"max\": 15},\n",
    "#     \"max_iter\": {\"type\": \"int\", \"min\": 100, \"max\": 300},\n",
    "#     \"min_samples_leaf\": {\"type\": \"int\", \"min\": 5, \"max\": 15},\n",
    "#     \"l2_regularization\": {\"type\": \"float\", \"min\": 0.5, \"max\": 3.0},\n",
    "#     \"max_leaf_nodes\": {\"type\": \"int\", \"min\": 40, \"max\": 90}\n",
    "# }\n",
    "\n",
    "# hgbc_tuner = HyperparameterTuner(HistGradientBoostingClassifier, params, train_x, train_y)\n",
    "# hgbc_tuner.optimize(100)\n",
    "# hgbc_tuner.best_params(), hgbc_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78      1060\n",
      "           1       0.78      0.79      0.78      1054\n",
      "\n",
      "    accuracy                           0.78      2114\n",
      "   macro avg       0.78      0.78      0.78      2114\n",
      "weighted avg       0.78      0.78      0.78      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"learning_rate\": 0.022119818280047138,\n",
    "    \"max_depth\": 12,\n",
    "    \"max_iter\": 276,\n",
    "    \"min_samples_leaf\": 5,\n",
    "    \"l2_regularization\": 0.9584267642328501,\n",
    "    \"max_leaf_nodes\": 44,\n",
    "}\n",
    "\n",
    "\n",
    "hgbc_final = HistGradientBoostingClassifier(**params)\n",
    "hgbc_final.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, hgbc_final.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8852672657620565"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(valid_y, hgbc_final.predict_proba(valid_x)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"n_estimators\": {\"type\": \"int\", \"min\": 200, \"max\": 400},\n",
    "#     \"learning_rate\": {\"type\": \"float\", \"min\": 0.1, \"max\": 0.25},\n",
    "#     \"algorithm\": {\"type\": \"categorical\", \"values\": [\"SAMME.R\"]}\n",
    "# }\n",
    "\n",
    "# ada_tuner = HyperparameterTuner(AdaBoostClassifier, params, train_x, train_y)\n",
    "# ada_tuner.optimize(50)\n",
    "# ada_tuner.best_params(), ada_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kwon3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74      1060\n",
      "           1       0.74      0.71      0.73      1054\n",
      "\n",
      "    accuracy                           0.73      2114\n",
      "   macro avg       0.73      0.73      0.73      2114\n",
      "weighted avg       0.73      0.73      0.73      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 358,\n",
    "    \"learning_rate\": 0.13883883597100793,\n",
    "    \"algorithm\": \"SAMME.R\",\n",
    "}\n",
    "\n",
    "\n",
    "ada_final = AdaBoostClassifier(**params)\n",
    "ada_final.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, ada_final.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8069045146969318"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(valid_y, ada_final.predict_proba(valid_x)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"C\": {\"type\": \"float\", \"min\": 0.1, \"max\": 0.5},\n",
    "#     \"kernel\": {\"type\": \"categorical\", \"values\": [\"linear\"]},\n",
    "#     \"degree\": {\"type\": \"int\", \"min\": 3, \"max\": 5},\n",
    "#     \"gamma\": {\"type\": \"float\", \"min\": 0.4, \"max\": 0.9},\n",
    "#     \"coef0\": {\"type\": \"float\", \"min\": 1.5, \"max\": 4.0},\n",
    "#     \"class_weight\": {\"type\": \"categorical\", \"values\": [None]}\n",
    "# }\n",
    "\n",
    "# svc_tuner = HyperparameterTuner(SVC, params, train_x, train_y)\n",
    "# svc_tuner.optimize(100)\n",
    "# svc_tuner.best_params(), svc_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.63      0.67      1060\n",
      "           1       0.67      0.75      0.71      1054\n",
      "\n",
      "    accuracy                           0.69      2114\n",
      "   macro avg       0.69      0.69      0.69      2114\n",
      "weighted avg       0.69      0.69      0.69      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"C\": 0.21950805677161292,\n",
    "    \"kernel\": \"linear\",\n",
    "    \"degree\": 4,\n",
    "    \"gamma\": 0.671045772731431,\n",
    "    \"coef0\": 2.7929809033044726,\n",
    "    \"class_weight\": None,\n",
    "}\n",
    "\n",
    "svc_final = SVC(**params, probability=True)\n",
    "svc_final.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, svc_final.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7805037413626437"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(valid_y, svc_final.predict_proba(valid_x)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"n_estimators\": {\"type\": \"int\", \"min\": 300, \"max\": 400},\n",
    "#     \"learning_rate\": {\"type\": \"float\", \"min\": 0.005, \"max\": 0.02},\n",
    "#     \"max_depth\": {\"type\": \"int\", \"min\": 4, \"max\": 6},\n",
    "#     \"min_child_weight\": {\"type\": \"int\", \"min\": 2, \"max\": 4},\n",
    "#     \"gamma\": {\"type\": \"float\", \"min\": 0.1, \"max\": 0.4},\n",
    "#     \"subsample\": {\"type\": \"float\", \"min\": 0.8, \"max\": 1.0},\n",
    "#     \"colsample_bytree\": {\"type\": \"float\", \"min\": 0.9, \"max\": 1.0},\n",
    "#     \"reg_alpha\": {\"type\": \"float\", \"min\": 0.05, \"max\": 0.2},\n",
    "#     \"reg_lambda\": {\"type\": \"float\", \"min\": 3.0, \"max\": 4.5}\n",
    "# }\n",
    "\n",
    "# sgb_tuner = HyperparameterTuner(XGBClassifier, params, train_x, train_y)\n",
    "# sgb_tuner.optimize(100)\n",
    "# sgb_tuner.best_params(), sgb_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78      1060\n",
      "           1       0.78      0.80      0.79      1054\n",
      "\n",
      "    accuracy                           0.79      2114\n",
      "   macro avg       0.79      0.79      0.79      2114\n",
      "weighted avg       0.79      0.79      0.79      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 337,\n",
    "    \"learning_rate\": 0.015272630148352066,\n",
    "    \"max_depth\": 5,\n",
    "    \"min_child_weight\": 2,\n",
    "    \"gamma\": 0.24988522273215766,\n",
    "    \"subsample\": 0.9639840429354903,\n",
    "    \"colsample_bytree\": 0.985608479043216,\n",
    "    \"reg_alpha\": 0.1856156681311941,\n",
    "    \"reg_lambda\": 3.4637470458659014,\n",
    "}\n",
    "\n",
    "\n",
    "xgb_final = XGBClassifier(**params)\n",
    "\n",
    "xgb_final.fit(train_x, train_y)\n",
    "\n",
    "print(classification_report(valid_y, xgb_final.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8745086105044574"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(valid_y, xgb_final.predict_proba(valid_x)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### category 형식 컬럼이 포함된 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_patch = cat_train_ft[\"patch\"].quantile(0.8)\n",
    "train_games = cat_train_ft[cat_train_ft[\"patch\"] < cutoff_patch][\"gameid\"].unique()\n",
    "valid_games = cat_train_ft[cat_train_ft[\"patch\"] >= cutoff_patch][\"gameid\"].unique()\n",
    "\n",
    "cat_train_x = cat_train_ft[cat_train_ft[\"gameid\"].isin(train_games)][cat_pre_game_features]\n",
    "cat_valid_x = cat_train_ft[cat_train_ft[\"gameid\"].isin(valid_games)][cat_pre_game_features]\n",
    "\n",
    "cat_train_y = teams_train_target[teams_train_target[\"gameid\"].isin(train_games)][\"result\"]\n",
    "cat_valid_y = teams_train_target[teams_train_target[\"gameid\"].isin(valid_games)][\"result\"]\n",
    "\n",
    "cat_train_x.drop(columns=[\"gameid\"], inplace=True)\n",
    "cat_valid_x.drop(columns=[\"gameid\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['league',\n",
       " 'teamname',\n",
       " 'opp_teamname',\n",
       " 'ban1',\n",
       " 'ban2',\n",
       " 'ban3',\n",
       " 'ban4',\n",
       " 'ban5',\n",
       " 'pick1',\n",
       " 'pick2',\n",
       " 'pick3',\n",
       " 'pick4',\n",
       " 'pick5']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = cat_train_x.select_dtypes(\"category\").columns.tolist()\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"iterations\": {\"type\": \"int\", \"min\": 300, \"max\": 600},\n",
    "#     \"learning_rate\": {\"type\": \"float\", \"min\": 0.15, \"max\": 0.3},\n",
    "#     \"depth\": {\"type\": \"int\", \"min\": 8, \"max\": 12},\n",
    "#     \"l2_leaf_reg\": {\"type\": \"float\", \"min\": 6.0, \"max\": 10.0},\n",
    "#     \"min_child_samples\": {\"type\": \"int\", \"min\": 8, \"max\": 16},\n",
    "#     \"max_bin\": {\"type\": \"int\", \"min\": 300, \"max\": 400},\n",
    "#     \"verbose\": {\"type\": \"int\", \"min\": 100, \"max\": 100}\n",
    "# }\n",
    "\n",
    "# cat_tuner = HyperparameterTuner(CatBoostClassifier, params, cat_train_x, cat_train_y, cat_features)\n",
    "# cat_tuner.optimize(20)\n",
    "# cat_tuner.best_params(), cat_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6079555\ttotal: 329ms\tremaining: 2m 15s\n",
      "100:\tlearn: 0.1385176\ttotal: 22.5s\tremaining: 1m 9s\n",
      "200:\tlearn: 0.0588177\ttotal: 46.2s\tremaining: 48.8s\n",
      "300:\tlearn: 0.0327123\ttotal: 1m 8s\tremaining: 25.4s\n",
      "400:\tlearn: 0.0213888\ttotal: 1m 30s\tremaining: 2.69s\n",
      "412:\tlearn: 0.0205659\ttotal: 1m 32s\tremaining: 0us\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1060\n",
      "           1       0.79      0.77      0.78      1054\n",
      "\n",
      "    accuracy                           0.78      2114\n",
      "   macro avg       0.78      0.78      0.78      2114\n",
      "weighted avg       0.78      0.78      0.78      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"iterations\": 413,\n",
    "    \"learning_rate\": 0.24110432469185597,\n",
    "    \"depth\": 10,\n",
    "    \"l2_leaf_reg\": 8.905869555950142,\n",
    "    \"min_child_samples\": 12,\n",
    "    \"max_bin\": 342,\n",
    "    \"verbose\": 100,\n",
    "}\n",
    "\n",
    "cat_final = CatBoostClassifier(**params, cat_features=cat_features)\n",
    "cat_final.fit(cat_train_x, cat_train_y)\n",
    "print(classification_report(cat_valid_y, cat_final.predict(cat_valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.876698829257814"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(cat_valid_y, cat_final.predict_proba(cat_valid_x)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78      1060\n",
      "           1       0.78      0.79      0.78      1054\n",
      "\n",
      "    accuracy                           0.78      2114\n",
      "   macro avg       0.78      0.78      0.78      2114\n",
      "weighted avg       0.78      0.78      0.78      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [\n",
    "    # (\"lr\", lr_final),\n",
    "    (\"lgbm\", lgbm_final),\n",
    "    (\"rf\", rf_final),\n",
    "    (\"hgbc\", hgbc_final),\n",
    "    # (\"ada\", ada_final),\n",
    "    # (\"svc\", svc_final),\n",
    "    (\"xgb\", xgb_final),\n",
    "]\n",
    "\n",
    "final_estimator = LogisticRegression(random_state=SEED)\n",
    "stacking_clf = StackingClassifier(estimators, final_estimator)\n",
    "stacking_clf.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, stacking_clf.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8849701049013641"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(valid_y, stacking_clf.predict_proba(valid_x)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1060\n",
      "           1       0.80      0.79      0.79      1054\n",
      "\n",
      "    accuracy                           0.80      2114\n",
      "   macro avg       0.80      0.80      0.80      2114\n",
      "weighted avg       0.80      0.80      0.80      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stacking_proba = stacking_clf.predict_proba(valid_x)\n",
    "cat_proba = cat_final.predict_proba(cat_valid_x)\n",
    "\n",
    "final_proba = 0.5 * stacking_proba + 0.5 * cat_proba\n",
    "\n",
    "final_pred = (final_proba[:, 1] >= 0.5).astype(int)\n",
    "print(classification_report(valid_y, final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8907647416848663"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(valid_y, final_proba[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6275820\ttotal: 235ms\tremaining: 1m 36s\n",
      "100:\tlearn: 0.1691727\ttotal: 24.2s\tremaining: 1m 14s\n",
      "200:\tlearn: 0.0750971\ttotal: 49s\tremaining: 51.6s\n",
      "300:\tlearn: 0.0393156\ttotal: 1m 13s\tremaining: 27.4s\n",
      "400:\tlearn: 0.0253351\ttotal: 1m 38s\tremaining: 2.95s\n",
      "412:\tlearn: 0.0243252\ttotal: 1m 41s\tremaining: 0us\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1160\n",
      "           1       0.76      0.74      0.75      1164\n",
      "\n",
      "    accuracy                           0.76      2324\n",
      "   macro avg       0.76      0.76      0.76      2324\n",
      "weighted avg       0.76      0.76      0.76      2324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_ft = train_ft[train_x.columns]\n",
    "test_ft = test_ft[train_x.columns]\n",
    "cat_train_ft = cat_train_ft[cat_train_x.columns]\n",
    "cat_test_ft = cat_test_ft[cat_train_x.columns]\n",
    "\n",
    "stacking_clf.fit(train_ft, teams_train_target[\"result\"])\n",
    "cat_final.fit(cat_train_ft, teams_train_target[\"result\"])\n",
    "\n",
    "stacking_test_proba = stacking_clf.predict_proba(test_ft)\n",
    "cat_test_proba = cat_final.predict_proba(cat_test_ft)\n",
    "\n",
    "final_test_proba = 0.5 * stacking_test_proba + 0.5 * cat_test_proba\n",
    "final_test_pred = (final_test_proba[:, 1] >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(teams_test_target[\"result\"], final_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8421895366749617"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(teams_test_target[\"result\"], final_test_proba[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최종 예측 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6154152\ttotal: 320ms\tremaining: 2m 11s\n",
      "100:\tlearn: 0.1750981\ttotal: 35.6s\tremaining: 1m 50s\n",
      "200:\tlearn: 0.0849220\ttotal: 1m 9s\tremaining: 1m 13s\n",
      "300:\tlearn: 0.0483373\ttotal: 1m 44s\tremaining: 38.9s\n",
      "400:\tlearn: 0.0301632\ttotal: 2m 19s\tremaining: 4.18s\n",
      "412:\tlearn: 0.0288545\ttotal: 2m 23s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.concat([train_ft, test_ft], ignore_index=True)\n",
    "cat_train_data = pd.concat([cat_train_ft, cat_test_ft], ignore_index=True)\n",
    "target_data = pd.concat([teams_train_target, teams_test_target], ignore_index=True)\n",
    "\n",
    "stacking_clf.fit(train_data, target_data[\"result\"])\n",
    "cat_final.fit(cat_train_data, target_data[\"result\"])\n",
    "\n",
    "joblib.dump(stacking_clf, \"output/stacking_0107.pkl\")\n",
    "cat_final.save_model(\"output/cat_0107.cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"output/cat_features.json\", \"w\") as f:\n",
    "    json.dump(cat_features, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
