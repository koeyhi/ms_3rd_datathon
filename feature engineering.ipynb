{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 111), (2324, 111), (9913, 3), (2324, 3))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = \"LoLesports_data/\"\n",
    "SEED = 42\n",
    "\n",
    "teams_train = pd.read_csv(f\"{DATA_PATH}teams_train.csv\")\n",
    "teams_test = pd.read_csv(f\"{DATA_PATH}teams_test.csv\")\n",
    "\n",
    "teams_train_target = pd.read_csv(f\"{DATA_PATH}teams_train_target.csv\")\n",
    "teams_test_target = pd.read_csv(f\"{DATA_PATH}teams_test_target.csv\")\n",
    "\n",
    "teams_train.shape, teams_test.shape, teams_train_target.shape, teams_test_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 컬럼 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상대 팀 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_opp_teams = teams_train.groupby(\"gameid\")[\"teamname\"].transform(lambda x: x.iloc[::-1].values).to_frame(\"opp_teamname\")\n",
    "teams_train = pd.concat([teams_train, temp_opp_teams], axis=1)\n",
    "temp_opp_teams = teams_test.groupby(\"gameid\")[\"teamname\"].transform(lambda x: x.iloc[::-1].values).to_frame(\"opp_teamname\")\n",
    "teams_test = pd.concat([teams_test, temp_opp_teams], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 날짜 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_train[\"date\"] = pd.to_datetime(teams_train[\"date\"])\n",
    "teams_test[\"date\"] = pd.to_datetime(teams_test[\"date\"])\n",
    "\n",
    "teams_train[\"year\"] = teams_train[\"date\"].dt.year\n",
    "teams_train[\"month\"] = teams_train[\"date\"].dt.month\n",
    "teams_train[\"day\"] = teams_train[\"date\"].dt.day\n",
    "\n",
    "teams_test[\"year\"] = teams_test[\"date\"].dt.year\n",
    "teams_test[\"month\"] = teams_test[\"date\"].dt.month\n",
    "teams_test[\"day\"] = teams_test[\"date\"].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 타입 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"league\", \"split\", \"teamname\", \"opp_teamname\", \"ban1\", \"ban2\", \"ban3\", \"ban4\", \"ban5\", \"pick1\", \"pick2\", \"pick3\", \"pick4\", \"pick5\"]\n",
    "\n",
    "teams_train[cols] = teams_train[cols].astype(\"category\")\n",
    "teams_test[cols] = teams_test[cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 특성 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df에 포함되어 있는 특성을 이용한 토대 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 19), (2324, 19))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_game_features = [\n",
    "    \"gameid\",\n",
    "    \"patch\",\n",
    "    \"side\",\n",
    "    \"league\",\n",
    "    \"teamname\",\n",
    "    \"opp_teamname\",\n",
    "    \"ban1\",\n",
    "    \"ban2\",\n",
    "    \"ban3\",\n",
    "    \"ban4\",\n",
    "    \"ban5\",\n",
    "    \"pick1\",\n",
    "    \"pick2\",\n",
    "    \"pick3\",\n",
    "    \"pick4\",\n",
    "    \"pick5\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"day\",\n",
    "]\n",
    "\n",
    "train_ft = teams_train[pre_game_features]\n",
    "test_ft = teams_test[pre_game_features]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 팀별 최근 10경기 지표 계산, 상대팀 최근 10경기 지표 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_columns = [\n",
    "    \"result\",\n",
    "    \"gamelength\",\n",
    "    \"kills\",\n",
    "    \"deaths\",\n",
    "    \"assists\",\n",
    "    \"firstblood\",\n",
    "    \"team kpm\",\n",
    "    \"ckpm\",\n",
    "    \"firstdragon\",\n",
    "    \"firstherald\",\n",
    "    \"void_grubs\",\n",
    "    \"firstbaron\",\n",
    "    \"firsttower\",\n",
    "    \"towers\",\n",
    "    \"firstmidtower\",\n",
    "    \"firsttothreetowers\",\n",
    "    \"turretplates\",\n",
    "    \"inhibitors\",\n",
    "    \"damagetochampions\",\n",
    "    \"dpm\",\n",
    "    \"damagetakenperminute\",\n",
    "    \"damagemitigatedperminute\",\n",
    "    \"wardsplaced\",\n",
    "    \"wpm\",\n",
    "    \"wardskilled\",\n",
    "    \"wcpm\",\n",
    "    \"controlwardsbought\",\n",
    "    \"visionscore\",\n",
    "    \"vspm\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 77), (2324, 77))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 팀별 최근 승률 계산을 위한 데이터 정렬\n",
    "temp_train = teams_train.sort_values(['teamname', 'year', 'month', 'day']).reset_index(drop=True)\n",
    "temp_test = teams_test.sort_values(['teamname', 'year', 'month', 'day']).reset_index(drop=True)\n",
    "\n",
    "# 팀별 최근 10경기 평균 계산\n",
    "for col in stats_columns:\n",
    "    # 승률 계산\n",
    "    recent10_train = temp_train.groupby('teamname', observed=True)[col].transform(\n",
    "        lambda x: x.rolling(window=10, min_periods=1).mean().shift(1)\n",
    "    )\n",
    "    train_ft = train_ft.assign(**{f'recent10_{col}': recent10_train})\n",
    "    \n",
    "    # 테스트 데이터의 지표 계산을 위해 훈련 데이터와 테스트 데이터 결합\n",
    "    combined_data = pd.concat([temp_train, temp_test], ignore_index=True).sort_values(['teamname', 'year', 'month', 'day'])\n",
    "    recent10_combined = combined_data.groupby('teamname', observed=True)[col].transform(\n",
    "        lambda x: x.rolling(window=10, min_periods=1).mean().shift(1)\n",
    "    )\n",
    "    combined_data = combined_data.assign(**{f'recent10_{col}': recent10_combined})\n",
    "\n",
    "    # 테스트 데이터의 지표 업데이트\n",
    "    recent10_test = combined_data.tail(len(temp_test))[f'recent10_{col}'].values\n",
    "    test_ft = test_ft.assign(**{f'recent10_{col}': recent10_test})\n",
    "    \n",
    "    # 상대팀 최근 지표 계산\n",
    "    merged_train = train_ft.merge(\n",
    "        train_ft[['teamname', 'year', 'month', 'day', f'recent10_{col}']], \n",
    "        left_on=['opp_teamname', 'year', 'month', 'day'],\n",
    "        right_on=['teamname', 'year', 'month', 'day'],\n",
    "        suffixes=('', '_opp')\n",
    "    )\n",
    "    train_ft = train_ft.assign(**{f'opp_recent10_{col}': merged_train[f'recent10_{col}_opp']})\n",
    "    \n",
    "    merged_test = test_ft.merge(\n",
    "        combined_data[['teamname', 'year', 'month', 'day', f'recent10_{col}']], \n",
    "        left_on=['opp_teamname', 'year', 'month', 'day'],\n",
    "        right_on=['teamname', 'year', 'month', 'day'],\n",
    "        suffixes=('', '_opp')\n",
    "    )\n",
    "    test_ft = test_ft.assign(**{f'opp_recent10_{col}': merged_test[f'recent10_{col}_opp']})\n",
    "    \n",
    "    # NaN값 처리 (첫 경기인 경우)\n",
    "    default_value = 0.5 if col == 'result' else 0\n",
    "    train_ft = train_ft.assign(**{\n",
    "        f'recent10_{col}': train_ft[f'recent10_{col}'].fillna(default_value),\n",
    "        f'opp_recent10_{col}': train_ft[f'opp_recent10_{col}'].fillna(default_value)\n",
    "    })\n",
    "    test_ft = test_ft.assign(**{\n",
    "        f'recent10_{col}': test_ft[f'recent10_{col}'].fillna(default_value),\n",
    "        f'opp_recent10_{col}': test_ft[f'opp_recent10_{col}'].fillna(default_value)\n",
    "    })\n",
    "    \n",
    "    # 특성 리스트에 새로운 지표 추가\n",
    "    pre_game_features.extend([f'recent10_{col}', f'opp_recent10_{col}'])\n",
    "\n",
    "# 입력 데이터 업데이트\n",
    "train_ft = train_ft[pre_game_features]\n",
    "test_ft = test_ft[pre_game_features]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상대 전적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 78), (2324, 78))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 팀별 맞대결 기록을 시간순으로 계산\n",
    "h2h_records = {}\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 결합 후 시간순 정렬\n",
    "combined_data = pd.concat([teams_train, teams_test], ignore_index=True)\n",
    "combined_data = combined_data.sort_values(['year', 'month', 'day'])\n",
    "\n",
    "# 각 경기마다 이전 맞대결 기록 계산\n",
    "h2h_winrates = []\n",
    "\n",
    "for idx, match in combined_data.iterrows():\n",
    "    team1, team2 = match['teamname'], match['opp_teamname']\n",
    "    year = match['year']\n",
    "    key = (team1, team2, year)\n",
    "    \n",
    "    # 현재 시점까지의 맞대결 기록 저장\n",
    "    if key not in h2h_records:\n",
    "        h2h_records[key] = {'wins': 0, 'total': 0}\n",
    "        h2h_winrates.append(0.5)  # 첫 맞대결인 경우 0.5 반환\n",
    "    else:\n",
    "        record = h2h_records[key]\n",
    "        h2h_winrates.append(record['wins'] / record['total'] if record['total'] > 0 else 0.5)\n",
    "    \n",
    "    # 현재 경기 결과 반영\n",
    "    result = match['result']\n",
    "    h2h_records[key]['total'] += 1\n",
    "    if result == 1:\n",
    "        h2h_records[key]['wins'] += 1\n",
    "        \n",
    "    # 상대팀 관점의 기록도 업데이트\n",
    "    key_reverse = (team2, team1, year)\n",
    "    if key_reverse not in h2h_records:\n",
    "        h2h_records[key_reverse] = {'wins': 0, 'total': 0}\n",
    "    h2h_records[key_reverse]['total'] += 1\n",
    "    if result == 0:\n",
    "        h2h_records[key_reverse]['wins'] += 1\n",
    "\n",
    "# 계산된 승률을 훈련/테스트 데이터에 할당\n",
    "train_ft['h2h_winrate'] = h2h_winrates[:len(teams_train)]\n",
    "test_ft['h2h_winrate'] = h2h_winrates[len(teams_train):]\n",
    "\n",
    "# 특성 리스트에 h2h_winrate 추가\n",
    "pre_game_features.append('h2h_winrate')\n",
    "\n",
    "# 입력 데이터 업데이트\n",
    "train_ft = train_ft[pre_game_features]\n",
    "test_ft = test_ft[pre_game_features]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 팀의 리그별 승률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 79), (2324, 79))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 팀별 리그 승률 기록을 저장할 딕셔너리\n",
    "league_records = {}\n",
    "league_winrates = []\n",
    "\n",
    "# 날짜순으로 정렬\n",
    "combined_data = pd.concat([teams_train, teams_test], ignore_index=True)\n",
    "combined_data = combined_data.sort_values('date')\n",
    "\n",
    "# 훈련 데이터에서 팀별 리그 승률 계산\n",
    "for idx, match in combined_data.iterrows():\n",
    "    team = match['teamname']\n",
    "    league = match['league']\n",
    "    year = match['year']\n",
    "    key = (team, league, year)\n",
    "    \n",
    "    # 현재 시점까지의 리그 승률 계산\n",
    "    if key not in league_records:\n",
    "        league_records[key] = {'wins': 0, 'total': 0}\n",
    "        league_winrates.append(0.5)  # 첫 경기인 경우 0.5 반환\n",
    "    else:\n",
    "        record = league_records[key]\n",
    "        league_winrates.append(record['wins'] / record['total'] if record['total'] > 0 else 0.5)\n",
    "    \n",
    "    # 현재 경기 결과 반영\n",
    "    result = match['result']\n",
    "    league_records[key]['total'] += 1\n",
    "    if result == 1:\n",
    "        league_records[key]['wins'] += 1\n",
    "\n",
    "# 계산된 승률을 훈련/테스트 데이터에 할당\n",
    "train_ft['league_winrate'] = league_winrates[:len(teams_train)]\n",
    "test_ft['league_winrate'] = league_winrates[len(teams_train):]\n",
    "\n",
    "# 특성 리스트에 league_winrate 추가\n",
    "pre_game_features.append('league_winrate')\n",
    "\n",
    "# 입력 데이터 업데이트\n",
    "train_ft = train_ft[pre_game_features]\n",
    "test_ft = test_ft[pre_game_features]\n",
    "\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 패치 버전 사이드별 승률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 패치 버전 사이드별 승률 기록을 저장할 딕셔너리\n",
    "# patch_side_records = {}\n",
    "# patch_side_winrates = []\n",
    "\n",
    "# # 날짜순으로 정렬\n",
    "# combined_data = pd.concat([teams_train, teams_test], ignore_index=True)\n",
    "# combined_data = combined_data.sort_values('date')\n",
    "\n",
    "# # 패치/사이드별 승률 계산\n",
    "# for idx, match in combined_data.iterrows():\n",
    "#     patch = match['patch']\n",
    "#     side = match['side']\n",
    "#     key = (patch, side)\n",
    "    \n",
    "#     # 현재 시점까지의 패치/사이드별 승률 계산\n",
    "#     if key not in patch_side_records:\n",
    "#         patch_side_records[key] = {'wins': 0, 'total': 0}\n",
    "#         patch_side_winrates.append(0.5)  # 첫 경기인 경우 0.5 반환\n",
    "#     else:\n",
    "#         record = patch_side_records[key]\n",
    "#         patch_side_winrates.append(record['wins'] / record['total'] if record['total'] > 0 else 0.5)\n",
    "    \n",
    "#     # 현재 경기 결과 반영\n",
    "#     result = match['result']\n",
    "#     patch_side_records[key]['total'] += 1\n",
    "#     if result == 1:\n",
    "#         patch_side_records[key]['wins'] += 1\n",
    "\n",
    "# # 계산된 승률을 훈련/테스트 데이터에 할당\n",
    "# train_ft['patch_side_winrate'] = patch_side_winrates[:len(teams_train)]\n",
    "# test_ft['patch_side_winrate'] = patch_side_winrates[len(teams_train):]\n",
    "\n",
    "# # 특성 리스트에 patch_side_winrate 추가\n",
    "# pre_game_features.append('patch_side_winrate')\n",
    "\n",
    "# # 입력 데이터 업데이트\n",
    "# train_ft = train_ft[pre_game_features]\n",
    "# test_ft = test_ft[pre_game_features]\n",
    "\n",
    "# train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 픽 챔피언 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = teams_train.copy()\n",
    "# df = df.sort_values([\"teamname\", \"date\", \"gameid\"])  # 시계열 정렬\n",
    "\n",
    "# for slot in [\"pick1\", \"pick2\", \"pick3\", \"pick4\", \"pick5\"]:\n",
    "#     # 1) 챔피언 컬럼 만들기\n",
    "#     df_pick = df[[\"gameid\", \"teamname\", \"date\", \"result\", slot]].copy()\n",
    "#     df_pick.rename(columns={slot: \"champion\"}, inplace=True)\n",
    "\n",
    "#     # 2) 챔피언을 category로 바꾸면 메모리 절약에 도움\n",
    "#     df_pick[\"champion\"] = df_pick[\"champion\"].astype(\"category\")\n",
    "\n",
    "#     # 3) groupby + cumsum + shift(1)로 \"직전까지\" 누적\n",
    "#     df_pick[\"pick_ind\"] = 1\n",
    "#     df_pick[\"win_ind\"] = (df_pick[\"result\"] == 1).astype(int)\n",
    "\n",
    "#     df_pick[\"cum_pick_count\"] = (\n",
    "#         df_pick.groupby([\"teamname\", \"champion\"], observed=True)[\"pick_ind\"].cumsum().shift(1)\n",
    "#     )\n",
    "#     df_pick[\"cum_win_count\"] = (\n",
    "#         df_pick.groupby([\"teamname\", \"champion\"], observed=True)[\"win_ind\"].cumsum().shift(1)\n",
    "#     )\n",
    "#     df_pick[\"cum_win_rate\"] = (\n",
    "#         df_pick[\"cum_win_count\"] / df_pick[\"cum_pick_count\"]\n",
    "#     ).fillna(0)\n",
    "\n",
    "#     # 4) 필요한 컬럼만 남겨서, 컬럼 이름으로 바꾸기\n",
    "#     df_pick = df_pick[\n",
    "#         [\"gameid\", \"teamname\", \"date\", \"champion\", \"cum_pick_count\", \"cum_win_rate\"]\n",
    "#     ].copy()\n",
    "\n",
    "#     df_pick.rename(\n",
    "#         columns={\n",
    "#             \"champion\": f\"{slot}_champion\",  # 구분용\n",
    "#             \"cum_pick_count\": f\"{slot}_cum_pick_count\",\n",
    "#             \"cum_win_rate\": f\"{slot}_cum_win_rate\",\n",
    "#         },\n",
    "#         inplace=True,\n",
    "#     )\n",
    "    \n",
    "#     # 5) 원본 df와 merge\n",
    "#     df = pd.merge(\n",
    "#         df,\n",
    "#         df_pick[\n",
    "#             [\n",
    "#                 \"gameid\",\n",
    "#                 \"teamname\",\n",
    "#                 \"date\",\n",
    "#                 f\"{slot}_champion\",\n",
    "#                 f\"{slot}_cum_pick_count\",\n",
    "#                 f\"{slot}_cum_win_rate\",\n",
    "#             ]\n",
    "#         ],\n",
    "#         left_on=[\"gameid\", \"teamname\", \"date\", f\"{slot}\"],  # 조인 키\n",
    "#         right_on=[\"gameid\", \"teamname\", \"date\", f\"{slot}_champion\"],\n",
    "#         how=\"left\",\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft[\"side\"] = train_ft[\"side\"].map({\"Blue\": 0, \"Red\": 1}) # 진영 인코딩\n",
    "test_ft[\"side\"] = test_ft[\"side\"].map({\"Blue\": 0, \"Red\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train_ft = train_ft.copy()\n",
    "cat_test_ft = test_ft.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def preprocess(train_ft, test_ft):\n",
    "    champion_columns_teams = ['ban1', 'ban2', 'ban3', 'ban4', 'ban5', 'pick1', 'pick2', 'pick3', 'pick4', 'pick5'] # 챔피언 레이블인코딩\n",
    "\n",
    "    champions = pd.concat([\n",
    "        train_ft[champion_columns_teams],\n",
    "        test_ft[champion_columns_teams],\n",
    "    ]).stack().unique()\n",
    "\n",
    "    champions_df = pd.DataFrame({'champion': champions})\n",
    "    champions_df = champions_df.dropna().reset_index(drop=True)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    champions_df['champion_encoded'] = le.fit_transform(champions_df['champion'])\n",
    "\n",
    "    for col in champion_columns_teams:\n",
    "        train_ft[col] = le.transform(train_ft[col])\n",
    "        test_ft[col] = le.transform(test_ft[col])\n",
    "        \n",
    "    encoder = OneHotEncoder() # 리그 원핫인코딩\n",
    "    league_encoded = encoder.fit_transform(train_ft[[\"league\"]]).toarray()\n",
    "    league_cols = [f\"league_{col}\" for col in encoder.categories_[0]]\n",
    "    train_ft = pd.concat(\n",
    "        [train_ft, pd.DataFrame(league_encoded, columns=league_cols)], axis=1\n",
    "    )\n",
    "    train_ft.drop(\"league\", axis=1, inplace=True)\n",
    "\n",
    "    league_encoded = encoder.transform(test_ft[[\"league\"]]).toarray()\n",
    "    test_ft = pd.concat(\n",
    "        [test_ft, pd.DataFrame(league_encoded, columns=league_cols)], axis=1\n",
    "    )\n",
    "    test_ft.drop(\"league\", axis=1, inplace=True)\n",
    "\n",
    "    le_team = LabelEncoder()\n",
    "    all_team_names = pd.concat(\n",
    "        [\n",
    "            train_ft[\"teamname\"],\n",
    "            test_ft[\"teamname\"],\n",
    "            train_ft[\"opp_teamname\"],\n",
    "            test_ft[\"opp_teamname\"],\n",
    "        ]\n",
    "    )\n",
    "    le_team.fit(all_team_names)\n",
    "\n",
    "    train_ft[\"teamname\"] = le_team.transform(train_ft[\"teamname\"])\n",
    "    train_ft[\"opp_teamname\"] = le_team.transform(train_ft[\"opp_teamname\"])\n",
    "\n",
    "    test_ft[\"teamname\"] = le_team.transform(test_ft[\"teamname\"])\n",
    "    test_ft[\"opp_teamname\"] = le_team.transform(test_ft[\"opp_teamname\"])\n",
    "    \n",
    "    return train_ft, test_ft\n",
    "\n",
    "train_ft, test_ft = preprocess(train_ft, test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['gameid'], dtype='object'), Index(['gameid'], dtype='object'))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.select_dtypes(\"object\").columns, test_ft.select_dtypes(\"object\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9913, 86), (2324, 86), (9913, 79), (2324, 79))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "def scale(train_ft, test_ft):\n",
    "    train_ft[train_ft.select_dtypes(\"number\").columns] = scaler.fit_transform(\n",
    "        train_ft[train_ft.select_dtypes(\"number\").columns]\n",
    "    )\n",
    "    test_ft[test_ft.select_dtypes(\"number\").columns] = scaler.transform(\n",
    "        test_ft[test_ft.select_dtypes(\"number\").columns]\n",
    "    )\n",
    "    return train_ft, test_ft\n",
    "\n",
    "\n",
    "train_ft, test_ft = scale(train_ft, test_ft)\n",
    "cat_train_ft, cat_test_ft = scale(cat_train_ft, cat_test_ft)\n",
    "\n",
    "train_ft.shape, test_ft.shape, cat_train_ft.shape, cat_test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습 및 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하이퍼파라미터 튜닝 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "\n",
    "class HyperparameterTuner:\n",
    "    def __init__(self, model, params, train, target, cat_features=None):\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "        self.train = train\n",
    "        self.target = target\n",
    "        self.cat_features = cat_features\n",
    "        self.cv = TimeSeriesSplit(n_splits=5)\n",
    "        self.study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "    def objective(self, trial):\n",
    "        params = {}\n",
    "        \n",
    "        for param_name, param_range in self.params.items():\n",
    "            if param_range[\"type\"] == \"int\":\n",
    "                params[param_name] = trial.suggest_int(\n",
    "                    param_name, param_range[\"min\"], param_range[\"max\"]\n",
    "                )\n",
    "            elif param_range[\"type\"] == \"float\":\n",
    "                params[param_name] = trial.suggest_float(\n",
    "                    param_name, param_range[\"min\"], param_range[\"max\"]\n",
    "                )\n",
    "            elif param_range[\"type\"] == \"categorical\":\n",
    "                params[param_name] = trial.suggest_categorical(\n",
    "                    param_name, param_range[\"values\"]\n",
    "                )\n",
    "        if self.model == CatBoostClassifier:\n",
    "            model = self.model(**params, cat_features=self.cat_features)\n",
    "        else:\n",
    "            model = self.model(**params)\n",
    "\n",
    "        model.fit(self.train, self.target)\n",
    "            \n",
    "        scores = cross_val_score(\n",
    "            model, self.train, self.target, cv=self.cv, scoring=\"accuracy\", n_jobs=-1\n",
    "        ).mean()\n",
    "        return scores\n",
    "\n",
    "    def optimize(self, n_trials):\n",
    "        self.study.optimize(self.objective, n_trials=n_trials)\n",
    "\n",
    "    def best_params(self):\n",
    "        return self.study.best_params\n",
    "\n",
    "    def best_score(self):\n",
    "        return self.study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모든 컬럼 형식이 number인 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7799, 77), (2114, 77))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_game_features.remove(\"league\")\n",
    "\n",
    "cutoff_patch = train_ft[\"patch\"].quantile(0.8)\n",
    "train_games = train_ft[train_ft[\"patch\"] < cutoff_patch][\"gameid\"].unique()\n",
    "valid_games = train_ft[train_ft[\"patch\"] >= cutoff_patch][\"gameid\"].unique()\n",
    "\n",
    "train_x = train_ft[train_ft[\"gameid\"].isin(train_games)][pre_game_features]\n",
    "valid_x = train_ft[train_ft[\"gameid\"].isin(valid_games)][pre_game_features]\n",
    "\n",
    "train_y = teams_train_target[teams_train_target[\"gameid\"].isin(train_games)][\"result\"]\n",
    "valid_y = teams_train_target[teams_train_target[\"gameid\"].isin(valid_games)][\"result\"]\n",
    "\n",
    "train_x.drop(columns=[\"gameid\"], inplace=True)\n",
    "valid_x.drop(columns=[\"gameid\"], inplace=True)\n",
    "\n",
    "train_x.shape, valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression : 0.6672825250192456, 0.024409093443106985\n",
      "LGBMClassifier : 0.7128560431100845, 0.045051417100336576\n",
      "RandomForestClassifier : 0.6574287913779832, 0.03637606863793496\n",
      "HistGradientBoostingClassifier : 0.7148575827559661, 0.05088430643347407\n",
      "AdaBoostClassifier : 0.6578906851424172, 0.03447087991368207\n",
      "SVC : 0.6568129330254042, 0.024746664599418874\n",
      "XGBClassifier : 0.7086989992301771, 0.03751368595997046\n",
      "CatBoostClassifier : 0.7026943802925327, 0.03815527050932491\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    LogisticRegression(random_state=SEED),\n",
    "    LGBMClassifier(random_state=SEED, n_jobs=-1),\n",
    "    RandomForestClassifier(random_state=SEED, n_jobs=-1),\n",
    "    HistGradientBoostingClassifier(random_state=SEED),\n",
    "    AdaBoostClassifier(random_state=SEED),\n",
    "    SVC(random_state=SEED),\n",
    "    XGBClassifier(random_state=SEED, n_jobs=-1),\n",
    "    CatBoostClassifier(random_state=SEED, verbose=0),\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    scores = cross_val_score(model, train_x, train_y, cv=TimeSeriesSplit(5), scoring=\"accuracy\", n_jobs=-1)\n",
    "    print(f\"{model.__class__.__name__} : {np.mean(scores)}, {np.std(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"C\": {\"type\": \"float\", \"min\": 0.01, \"max\": 10},\n",
    "#     \"penalty\": {\"type\": \"categorical\", \"values\": [\"l1\", \"l2\"]},\n",
    "#     \"solver\": {\"type\": \"categorical\", \"values\": [\"liblinear\", \"saga\"]},\n",
    "#     \"max_iter\": {\"type\": \"int\", \"min\": 100, \"max\": 2000},\n",
    "# }\n",
    "\n",
    "# lr_vt_tuner = HyperparameterTuner(LogisticRegression, params, train_x, train_y)\n",
    "# lr_vt_tuner.optimize(100)\n",
    "# lr_vt_tuner.best_params(), lr_vt_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.64      0.67      1060\n",
      "           1       0.67      0.73      0.70      1054\n",
      "\n",
      "    accuracy                           0.69      2114\n",
      "   macro avg       0.69      0.69      0.68      2114\n",
      "weighted avg       0.69      0.69      0.68      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"C\": 0.38414964961856957,\n",
    "    \"penalty\": \"l1\",\n",
    "    \"solver\": \"liblinear\",\n",
    "    \"max_iter\": 1903\n",
    "}\n",
    "\n",
    "lr_final = LogisticRegression(**params)\n",
    "lr_final.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, lr_final.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"n_estimators\": {\"type\": \"int\", \"min\": 100, \"max\": 300},\n",
    "#     \"learning_rate\": {\"type\": \"float\", \"min\": 0.01, \"max\": 0.1}, \n",
    "#     \"max_depth\": {\"type\": \"int\", \"min\": 8, \"max\": 12},\n",
    "#     \"num_leaves\": {\"type\": \"int\", \"min\": 100, \"max\": 150},\n",
    "#     \"min_child_samples\": {\"type\": \"int\", \"min\": 5, \"max\": 15},\n",
    "#     \"subsample\": {\"type\": \"float\", \"min\": 0.5, \"max\": 0.7},\n",
    "#     \"colsample_bytree\": {\"type\": \"float\", \"min\": 0.4, \"max\": 0.6},\n",
    "#     \"reg_alpha\": {\"type\": \"float\", \"min\": 0.001, \"max\": 0.1},\n",
    "#     \"reg_lambda\": {\"type\": \"float\", \"min\": 3.0, \"max\": 6.0},\n",
    "#     \"verbose\": {\"type\": \"int\", \"min\": -1, \"max\": -1}\n",
    "# }\n",
    "\n",
    "# lgbm_tuner = HyperparameterTuner(LGBMClassifier, params, train_x, train_y)\n",
    "# lgbm_tuner.optimize(100)\n",
    "# lgbm_tuner.best_params(), lgbm_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78      1060\n",
      "           1       0.78      0.79      0.78      1054\n",
      "\n",
      "    accuracy                           0.78      2114\n",
      "   macro avg       0.78      0.78      0.78      2114\n",
      "weighted avg       0.78      0.78      0.78      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 285,\n",
    "    \"learning_rate\": 0.023007542937157222,\n",
    "    \"max_depth\": 9,\n",
    "    \"num_leaves\": 101,\n",
    "    \"min_child_samples\": 9,\n",
    "    \"subsample\": 0.6754653255644233,\n",
    "    \"colsample_bytree\": 0.5153479009794544,\n",
    "    \"reg_alpha\": 0.07512515626736012,\n",
    "    \"reg_lambda\": 3.3370499751525755,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "lgbm_final = LGBMClassifier(**params)\n",
    "lgbm_final.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, lgbm_final.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"n_estimators\": {\"type\": \"int\", \"min\": 800, \"max\": 1100},\n",
    "#     \"max_depth\": {\"type\": \"int\", \"min\": 15, \"max\": 21},\n",
    "#     \"min_samples_split\": {\"type\": \"int\", \"min\": 15, \"max\": 23},\n",
    "#     \"min_samples_leaf\": {\"type\": \"int\", \"min\": 7, \"max\": 11},\n",
    "#     \"max_features\": {\"type\": \"float\", \"min\": 0.7, \"max\": 0.85},\n",
    "#     \"bootstrap\": {\"type\": \"categorical\", \"values\": [False]},\n",
    "#     \"class_weight\": {\"type\": \"categorical\", \"values\": [\"balanced\"]}\n",
    "# }\n",
    "\n",
    "# rf_tuner = HyperparameterTuner(RandomForestClassifier, params, train_x, train_y)\n",
    "# rf_tuner.optimize(20)\n",
    "# rf_tuner.best_params(), rf_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1060\n",
      "           1       0.76      0.81      0.78      1054\n",
      "\n",
      "    accuracy                           0.78      2114\n",
      "   macro avg       0.78      0.78      0.78      2114\n",
      "weighted avg       0.78      0.78      0.78      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 954,\n",
    "    \"max_depth\": 18,\n",
    "    \"min_samples_split\": 19,\n",
    "    \"min_samples_leaf\": 9,\n",
    "    \"max_features\": 0.7814902230628112,\n",
    "    \"bootstrap\": False,\n",
    "    \"class_weight\": \"balanced\",\n",
    "}\n",
    "\n",
    "rf_final = RandomForestClassifier(**params)\n",
    "rf_final.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, rf_final.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"learning_rate\": {\"type\": \"float\", \"min\": 0.01, \"max\": 0.1},\n",
    "#     \"max_depth\": {\"type\": \"int\", \"min\": 8, \"max\": 15},\n",
    "#     \"max_iter\": {\"type\": \"int\", \"min\": 100, \"max\": 300},\n",
    "#     \"min_samples_leaf\": {\"type\": \"int\", \"min\": 5, \"max\": 15},\n",
    "#     \"l2_regularization\": {\"type\": \"float\", \"min\": 0.5, \"max\": 3.0},\n",
    "#     \"max_leaf_nodes\": {\"type\": \"int\", \"min\": 40, \"max\": 90}\n",
    "# }\n",
    "\n",
    "# hgbc_tuner = HyperparameterTuner(HistGradientBoostingClassifier, params, train_x, train_y)\n",
    "# hgbc_tuner.optimize(100)\n",
    "# hgbc_tuner.best_params(), hgbc_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79      1060\n",
      "           1       0.78      0.79      0.79      1054\n",
      "\n",
      "    accuracy                           0.79      2114\n",
      "   macro avg       0.79      0.79      0.79      2114\n",
      "weighted avg       0.79      0.79      0.79      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"learning_rate\": 0.022119818280047138,\n",
    "    \"max_depth\": 12,\n",
    "    \"max_iter\": 276,\n",
    "    \"min_samples_leaf\": 5,\n",
    "    \"l2_regularization\": 0.9584267642328501,\n",
    "    \"max_leaf_nodes\": 44,\n",
    "}\n",
    "\n",
    "\n",
    "hgbc_final = HistGradientBoostingClassifier(**params)\n",
    "hgbc_final.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, hgbc_final.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"n_estimators\": {\"type\": \"int\", \"min\": 200, \"max\": 400},\n",
    "#     \"learning_rate\": {\"type\": \"float\", \"min\": 0.1, \"max\": 0.25},\n",
    "#     \"algorithm\": {\"type\": \"categorical\", \"values\": [\"SAMME.R\"]}\n",
    "# }\n",
    "\n",
    "# ada_tuner = HyperparameterTuner(AdaBoostClassifier, params, train_x, train_y)\n",
    "# ada_tuner.optimize(50)\n",
    "# ada_tuner.best_params(), ada_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kwon3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73      1060\n",
      "           1       0.73      0.73      0.73      1054\n",
      "\n",
      "    accuracy                           0.73      2114\n",
      "   macro avg       0.73      0.73      0.73      2114\n",
      "weighted avg       0.73      0.73      0.73      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 358,\n",
    "    \"learning_rate\": 0.13883883597100793,\n",
    "    \"algorithm\": \"SAMME.R\",\n",
    "}\n",
    "\n",
    "\n",
    "ada_final = AdaBoostClassifier(**params)\n",
    "\n",
    "ada_final.fit(train_x, train_y)\n",
    "\n",
    "print(classification_report(valid_y, ada_final.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"C\": {\"type\": \"float\", \"min\": 0.1, \"max\": 0.5},\n",
    "#     \"kernel\": {\"type\": \"categorical\", \"values\": [\"linear\"]},\n",
    "#     \"degree\": {\"type\": \"int\", \"min\": 3, \"max\": 5},\n",
    "#     \"gamma\": {\"type\": \"float\", \"min\": 0.4, \"max\": 0.9},\n",
    "#     \"coef0\": {\"type\": \"float\", \"min\": 1.5, \"max\": 4.0},\n",
    "#     \"class_weight\": {\"type\": \"categorical\", \"values\": [None]}\n",
    "# }\n",
    "\n",
    "# svc_tuner = HyperparameterTuner(SVC, params, train_x, train_y)\n",
    "# svc_tuner.optimize(100)\n",
    "# svc_tuner.best_params(), svc_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.67      1060\n",
      "           1       0.66      0.73      0.69      1054\n",
      "\n",
      "    accuracy                           0.68      2114\n",
      "   macro avg       0.68      0.68      0.68      2114\n",
      "weighted avg       0.68      0.68      0.68      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"C\": 0.21950805677161292,\n",
    "    \"kernel\": \"linear\",\n",
    "    \"degree\": 4,\n",
    "    \"gamma\": 0.671045772731431,\n",
    "    \"coef0\": 2.7929809033044726,\n",
    "    \"class_weight\": None,\n",
    "}\n",
    "\n",
    "svc_final = SVC(**params)\n",
    "svc_final.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, svc_final.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"n_estimators\": {\"type\": \"int\", \"min\": 300, \"max\": 400},\n",
    "#     \"learning_rate\": {\"type\": \"float\", \"min\": 0.005, \"max\": 0.02},\n",
    "#     \"max_depth\": {\"type\": \"int\", \"min\": 4, \"max\": 6},\n",
    "#     \"min_child_weight\": {\"type\": \"int\", \"min\": 2, \"max\": 4},\n",
    "#     \"gamma\": {\"type\": \"float\", \"min\": 0.1, \"max\": 0.4},\n",
    "#     \"subsample\": {\"type\": \"float\", \"min\": 0.8, \"max\": 1.0},\n",
    "#     \"colsample_bytree\": {\"type\": \"float\", \"min\": 0.9, \"max\": 1.0},\n",
    "#     \"reg_alpha\": {\"type\": \"float\", \"min\": 0.05, \"max\": 0.2},\n",
    "#     \"reg_lambda\": {\"type\": \"float\", \"min\": 3.0, \"max\": 4.5}\n",
    "# }\n",
    "\n",
    "# sgb_tuner = HyperparameterTuner(XGBClassifier, params, train_x, train_y)\n",
    "# sgb_tuner.optimize(100)\n",
    "# sgb_tuner.best_params(), sgb_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78      1060\n",
      "           1       0.77      0.80      0.79      1054\n",
      "\n",
      "    accuracy                           0.78      2114\n",
      "   macro avg       0.78      0.78      0.78      2114\n",
      "weighted avg       0.78      0.78      0.78      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 337,\n",
    "    \"learning_rate\": 0.015272630148352066,\n",
    "    \"max_depth\": 5,\n",
    "    \"min_child_weight\": 2,\n",
    "    \"gamma\": 0.24988522273215766,\n",
    "    \"subsample\": 0.9639840429354903,\n",
    "    \"colsample_bytree\": 0.985608479043216,\n",
    "    \"reg_alpha\": 0.1856156681311941,\n",
    "    \"reg_lambda\": 3.4637470458659014,\n",
    "}\n",
    "\n",
    "\n",
    "xgb_final = XGBClassifier(**params)\n",
    "\n",
    "xgb_final.fit(train_x, train_y)\n",
    "\n",
    "print(classification_report(valid_y, xgb_final.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### category 형식 컬럼이 포함된 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_patch = cat_train_ft[\"patch\"].quantile(0.8)\n",
    "train_games = cat_train_ft[cat_train_ft[\"patch\"] < cutoff_patch][\"gameid\"].unique()\n",
    "valid_games = cat_train_ft[cat_train_ft[\"patch\"] >= cutoff_patch][\"gameid\"].unique()\n",
    "\n",
    "cat_train_x = cat_train_ft[cat_train_ft[\"gameid\"].isin(train_games)][pre_game_features]\n",
    "cat_valid_x = cat_train_ft[cat_train_ft[\"gameid\"].isin(valid_games)][pre_game_features]\n",
    "\n",
    "cat_train_y = teams_train_target[teams_train_target[\"gameid\"].isin(train_games)][\"result\"]\n",
    "cat_valid_y = teams_train_target[teams_train_target[\"gameid\"].isin(valid_games)][\"result\"]\n",
    "\n",
    "cat_train_x.drop(columns=[\"gameid\"], inplace=True)\n",
    "cat_valid_x.drop(columns=[\"gameid\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = cat_train_x.select_dtypes(\"category\").columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"iterations\": {\"type\": \"int\", \"min\": 300, \"max\": 600},\n",
    "#     \"learning_rate\": {\"type\": \"float\", \"min\": 0.15, \"max\": 0.3},\n",
    "#     \"depth\": {\"type\": \"int\", \"min\": 8, \"max\": 12},\n",
    "#     \"l2_leaf_reg\": {\"type\": \"float\", \"min\": 6.0, \"max\": 10.0},\n",
    "#     \"min_child_samples\": {\"type\": \"int\", \"min\": 8, \"max\": 16},\n",
    "#     \"max_bin\": {\"type\": \"int\", \"min\": 300, \"max\": 400},\n",
    "#     \"verbose\": {\"type\": \"int\", \"min\": 100, \"max\": 100}\n",
    "# }\n",
    "\n",
    "# cat_tuner = HyperparameterTuner(CatBoostClassifier, params, cat_train_x, cat_train_y, cat_features)\n",
    "# cat_tuner.optimize(20)\n",
    "# cat_tuner.best_params(), cat_tuner.best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6229969\ttotal: 455ms\tremaining: 3m 7s\n",
      "100:\tlearn: 0.1265438\ttotal: 26.3s\tremaining: 1m 21s\n",
      "200:\tlearn: 0.0531274\ttotal: 52.6s\tremaining: 55.5s\n",
      "300:\tlearn: 0.0290406\ttotal: 1m 18s\tremaining: 29s\n",
      "400:\tlearn: 0.0193965\ttotal: 1m 42s\tremaining: 3.06s\n",
      "412:\tlearn: 0.0185556\ttotal: 1m 45s\tremaining: 0us\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      1060\n",
      "           1       0.78      0.75      0.76      1054\n",
      "\n",
      "    accuracy                           0.77      2114\n",
      "   macro avg       0.77      0.77      0.77      2114\n",
      "weighted avg       0.77      0.77      0.77      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"iterations\": 413,\n",
    "    \"learning_rate\": 0.24110432469185597,\n",
    "    \"depth\": 10,\n",
    "    \"l2_leaf_reg\": 8.905869555950142,\n",
    "    \"min_child_samples\": 12,\n",
    "    \"max_bin\": 342,\n",
    "    \"verbose\": 100,\n",
    "}\n",
    "\n",
    "cat_final = CatBoostClassifier(**params, cat_features=cat_features)\n",
    "cat_final.fit(cat_train_x, cat_train_y)\n",
    "print(classification_report(cat_valid_y, cat_final.predict(cat_valid_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1060\n",
      "           1       0.79      0.79      0.79      1054\n",
      "\n",
      "    accuracy                           0.79      2114\n",
      "   macro avg       0.79      0.79      0.79      2114\n",
      "weighted avg       0.79      0.79      0.79      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [\n",
    "    # (\"lr\", lr_final),\n",
    "    (\"lgbm\", lgbm_final),\n",
    "    (\"rf\", rf_final),\n",
    "    (\"hgbc\", hgbc_final),\n",
    "    # (\"ada\", ada_final),\n",
    "    # (\"svc\", svc_final),\n",
    "    (\"xgb\", xgb_final),\n",
    "]\n",
    "\n",
    "final_estimator = LogisticRegression(random_state=SEED)\n",
    "stacking_clf = StackingClassifier(estimators, final_estimator)\n",
    "stacking_clf.fit(train_x, train_y)\n",
    "print(classification_report(valid_y, stacking_clf.predict(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1060\n",
      "           1       0.79      0.78      0.79      1054\n",
      "\n",
      "    accuracy                           0.79      2114\n",
      "   macro avg       0.79      0.79      0.79      2114\n",
      "weighted avg       0.79      0.79      0.79      2114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stacking_proba = stacking_clf.predict_proba(valid_x)\n",
    "cat_proba = cat_final.predict_proba(cat_valid_x)\n",
    "\n",
    "final_proba = 0.5 * stacking_proba + 0.5 * cat_proba\n",
    "\n",
    "final_pred = (final_proba[:, 1] >= 0.5).astype(int)\n",
    "print(classification_report(valid_y, final_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6125006\ttotal: 252ms\tremaining: 1m 43s\n",
      "100:\tlearn: 0.1604703\ttotal: 27.9s\tremaining: 1m 26s\n",
      "200:\tlearn: 0.0659976\ttotal: 55.7s\tremaining: 58.7s\n",
      "300:\tlearn: 0.0356571\ttotal: 1m 24s\tremaining: 31.3s\n",
      "400:\tlearn: 0.0229581\ttotal: 1m 53s\tremaining: 3.39s\n",
      "412:\tlearn: 0.0221277\ttotal: 1m 57s\tremaining: 0us\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1160\n",
      "           1       0.76      0.76      0.76      1164\n",
      "\n",
      "    accuracy                           0.76      2324\n",
      "   macro avg       0.76      0.76      0.76      2324\n",
      "weighted avg       0.76      0.76      0.76      2324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_ft = train_ft[train_x.columns]\n",
    "test_ft = test_ft[train_x.columns]\n",
    "cat_train_ft = cat_train_ft[cat_train_x.columns]\n",
    "cat_test_ft = cat_test_ft[cat_train_x.columns]\n",
    "\n",
    "stacking_clf.fit(train_ft, teams_train_target[\"result\"])\n",
    "cat_final.fit(cat_train_ft, teams_train_target[\"result\"])\n",
    "\n",
    "stacking_test_proba = stacking_clf.predict_proba(test_ft)\n",
    "cat_test_proba = cat_final.predict_proba(cat_test_ft)\n",
    "\n",
    "final_test_proba = 0.5 * stacking_test_proba + 0.5 * cat_test_proba\n",
    "final_test_pred = (final_test_proba[:, 1] >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(teams_test_target[\"result\"], final_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최종 예측 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6224647\ttotal: 358ms\tremaining: 2m 27s\n",
      "100:\tlearn: 0.1767020\ttotal: 37.8s\tremaining: 1m 56s\n",
      "200:\tlearn: 0.0788264\ttotal: 1m 15s\tremaining: 1m 19s\n",
      "300:\tlearn: 0.0446790\ttotal: 1m 52s\tremaining: 41.9s\n",
      "400:\tlearn: 0.0286631\ttotal: 2m 29s\tremaining: 4.48s\n",
      "412:\tlearn: 0.0271961\ttotal: 2m 34s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['output/model2.pkl']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.concat([train_ft, test_ft], ignore_index=True)\n",
    "cat_train_data = pd.concat([cat_train_ft, cat_test_ft], ignore_index=True)\n",
    "target_data = pd.concat([teams_train_target, teams_test_target], ignore_index=True)\n",
    "\n",
    "stacking_clf.fit(train_data, target_data[\"result\"])\n",
    "cat_final.fit(cat_train_data, target_data[\"result\"])\n",
    "\n",
    "joblib.dump(stacking_clf, \"output/model1.pkl\")\n",
    "joblib.dump(cat_final, \"output/model2.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
